<!DOCTYPE html>
<html><head>
<title>Transparent Multilevel Diversion</title>




<meta charset="utf-8">
<meta name="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="">
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
<meta content="telephone=no" name="format-detection">
<meta name="description" content="透明多级分流">
<meta name="renderer" content="webkit">
<meta name="theme-color" content="#ffffff">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link rel="shortcut icon" href="/images/smile_favicon.ico" type="image/x-icon" />
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">



<meta property="og:title" content="Transparent Multilevel Diversion" />
<meta property="og:description" content="透明多级分流" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.openheart.icu/computing-science/transparent-multilevel-diversion-system/" />
<meta property="article:published_time" content="2021-12-01T14:28:00+00:00" />
<meta property="article:modified_time" content="2021-12-01T14:28:00+00:00" /><meta property="og:site_name" content="My Blog" />





<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Transparent Multilevel Diversion"/>
<meta name="twitter:description" content="透明多级分流"/>







<link type="text/css" rel="stylesheet" href="/vendor/css/bootstrap.min.css">


  






<link rel="stylesheet" href="https://www.openheart.icu/scss/journal.min.501d7307b277cc4885da27e54d8eb3a01eb04a3eb1539d4db0f640bad47a803c.css" integrity="sha256-UB1zB7J3zEiF2iflTY6zoB6wSj6xU51NsPZAutR6gDw=" media="screen">



<link rel="stylesheet" href="https://www.openheart.icu/scss/dark-mode.min.7757e4001197b1cd1c03bf75eeef947c882e0bbc26b5096a3c1a66992f55521a.css" integrity="sha256-d1fkABGXsc0cA7917u&#43;UfIguC7wmtQlqPBpmmS9VUho=" media="screen">


<script src="/vendor/js/loadCSS.js"></script>
<script>
  loadCSS("https://fonts.googleapis.com/css?family=Fira+Mono|Material+Icons");
</script>






  <script src="/js/toc.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="/vendor/js/md5.min.js"></script>
<script>
  var gitalk = new Gitalk({
  clientID: '78028e4d522031d4773c',
  clientSecret: 'e387ce8646bde4df55f81e9dc6c1e72b91248d82',
  repo: '42th-openheart',
  owner: 'KrisNie',
  admin: ['KrisNie'],
  id: md5(location.pathname),
  distractionFreeMode: 'false'
  });
  window.onload = function () {
        gitalk.render('gitalk-container')
  }
</script>












</head>
<body>
    	<div id="app"><div id="sideContainer" class="side-container">
    
    <a class="a-block nav-head false" href="https://www.openheart.icu/">
    
        <div class="nav-title">
            42th openheart
        </div>
        
        <div class="nav-subtitle">
            Kris Nie&#39;s Blog.
        </div>
        
    </a>

    <div class="nav-link-list">
        
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/arithmetic">
                Arithmetic
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/cs">
                ComputerScience
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/dotnet">
                DotNet
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/finance">
                Finance
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/speech">
                Speech
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/about">
                About
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/categories">
                Categories
            </a>
            
        
            
            
            
            
            
            <a class="a-block nav-link-item false" href="/tags">
                Tags
            </a>
            
        
    </div>

    

    <div class="nav-footer">
        


<i class="fa fa-weixin" aria-hidden="true"></i>
QuadragintaDuo
<br>
<i class="fa fa-envelope" aria-hidden="true"></i>
krisnie42@qq.com
<br>
<span id="busuanzi_container_site_pv">
    site pv:<span id="busuanzi_value_site_pv"></span>
</span>
| 
<span id="busuanzi_container_site_uv">
	site uv:<span id="busuanzi_value_site_uv"></span>
</span>
<br>
<a href="https://beian.miit.gov.cn/">鲁ICP备20007116号-1</a>
<br>
Powered by Hugo | Theme - <a href="https://github.com/amazingrise/hugo-theme-diary">Diary</a>

<br>


&copy;
	
	2022 ALL RIGHTS RESERVED KRIS NIE
	


    </div>
    
</div><div id="extraContainer" class="extra-container">
    
    
    <div class="toc animated-visibility" :class="{ invisible: scrollY <= 140 }">


	<div class="toc-content">
	
		
		
		
		<center>- CATALOG -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#client-cache" onclick="onNavClick(`#client-cache-nav`)" id="client-cache-nav">
									Client Cache
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#force-caching" onclick="onNavClick(`#force-caching-nav`)" id="force-caching-nav">
									Force Caching
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#negotiate-caching" onclick="onNavClick(`#negotiate-caching-nav`)" id="negotiate-caching-nav">
									Negotiate Caching
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#dns-lookup" onclick="onNavClick(`#dns-lookup-nav`)" id="dns-lookup-nav">
									DNS Lookup
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#transmission-optimization" onclick="onNavClick(`#transmission-optimization-nav`)" id="transmission-optimization-nav">
									Transmission Optimization
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#optimization-of-connections-number" onclick="onNavClick(`#optimization-of-connections-number-nav`)" id="optimization-of-connections-number-nav">
									Optimization of Connections&#39; Number
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#transfer-compression" onclick="onNavClick(`#transfer-compression-nav`)" id="transfer-compression-nav">
									Transfer Compression
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#quick-udp-internet-connections" onclick="onNavClick(`#quick-udp-internet-connections-nav`)" id="quick-udp-internet-connections-nav">
									Quick UDP Internet Connections
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#content-distribution-network" onclick="onNavClick(`#content-distribution-network-nav`)" id="content-distribution-network-nav">
									Content Distribution Network
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#route-resolution" onclick="onNavClick(`#route-resolution-nav`)" id="route-resolution-nav">
									Route Resolution
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#content-distribution" onclick="onNavClick(`#content-distribution-nav`)" id="content-distribution-nav">
									Content Distribution
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cdn-applications" onclick="onNavClick(`#cdn-applications-nav`)" id="cdn-applications-nav">
									CDN Applications
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#load-balancing" onclick="onNavClick(`#load-balancing-nav`)" id="load-balancing-nav">
									Load Balancing
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#data-link-layer" onclick="onNavClick(`#data-link-layer-nav`)" id="data-link-layer-nav">
									Data Link Layer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#network-layer" onclick="onNavClick(`#network-layer-nav`)" id="network-layer-nav">
									Network Layer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#application-layer" onclick="onNavClick(`#application-layer-nav`)" id="application-layer-nav">
									Application Layer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#balance-strategy" onclick="onNavClick(`#balance-strategy-nav`)" id="balance-strategy-nav">
									Balance Strategy
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cache" onclick="onNavClick(`#cache-nav`)" id="cache-nav">
									Cache
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#properties" onclick="onNavClick(`#properties-nav`)" id="properties-nav">
									Properties
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#throughput" onclick="onNavClick(`#throughput-nav`)" id="throughput-nav">
									Throughput
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#hit-rate--elimination-strategy" onclick="onNavClick(`#hit-rate--elimination-strategy-nav`)" id="hit-rate--elimination-strategy-nav">
									Hit rate &amp; Elimination Strategy
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#extended-functionality" onclick="onNavClick(`#extended-functionality-nav`)" id="extended-functionality-nav">
									Extended functionality
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#distributed-support" onclick="onNavClick(`#distributed-support-nav`)" id="distributed-support-nav">
									Distributed support
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#risks" onclick="onNavClick(`#risks-nav`)" id="risks-nav">
									Risks
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cache-penetration" onclick="onNavClick(`#cache-penetration-nav`)" id="cache-penetration-nav">
									Cache Penetration
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cache-breakdown" onclick="onNavClick(`#cache-breakdown-nav`)" id="cache-breakdown-nav">
									Cache Breakdown
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cache-avalanche" onclick="onNavClick(`#cache-avalanche-nav`)" id="cache-avalanche-nav">
									Cache Avalanche
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cache-pollution" onclick="onNavClick(`#cache-pollution-nav`)" id="cache-pollution-nav">
									Cache Pollution
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
								</ul>
							
						
						
						
							<li>
								<a href="#reference" onclick="onNavClick(`#reference-nav`)" id="reference-nav">
									Reference
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
    
    <div class="pagination">
        <a id="globalBackToTop" class="pagination-action animated-visibility" href="#top" :class="{ invisible: scrollY == 0 }">
            <i class="material-icons pagination-action-icon">
                keyboard_arrow_up
            </i>
        </a>
        
        <a type="button" class="pagination-action" id="darkModeToggleButton">
            <span class="material-icons pagination-action-icon" id="darkModeToggleIcon">
                dark_mode
            </span>
        </a>
        
        
    </div>
</div>
<div class="single-column-drawer-container" id="drawer"
     v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }">
    <div class="drawer-content">
        <div class="drawer-menu">
            
            
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/arithmetic">
                    Arithmetic
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/cs">
                    ComputerScience
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/dotnet">
                    DotNet
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/finance">
                    Finance
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/speech">
                    Speech
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/about">
                    About
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/categories">
                    Categories
                </a>
                
            
                
                
                
                
                
                <a class="a-block drawer-menu-item false" href="/tags">
                    Tags
                </a>
                
            
            
            <div class="toc">


	<div class="toc-content">
	
		
		
		
		<center>- CATALOG -</center>
		
		
		<ul>
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#client-cache" onclick="onNavClick(`#client-cache-nav`)" id="client-cache-nav">
									Client Cache
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#force-caching" onclick="onNavClick(`#force-caching-nav`)" id="force-caching-nav">
									Force Caching
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#negotiate-caching" onclick="onNavClick(`#negotiate-caching-nav`)" id="negotiate-caching-nav">
									Negotiate Caching
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#dns-lookup" onclick="onNavClick(`#dns-lookup-nav`)" id="dns-lookup-nav">
									DNS Lookup
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#transmission-optimization" onclick="onNavClick(`#transmission-optimization-nav`)" id="transmission-optimization-nav">
									Transmission Optimization
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#optimization-of-connections-number" onclick="onNavClick(`#optimization-of-connections-number-nav`)" id="optimization-of-connections-number-nav">
									Optimization of Connections&#39; Number
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#transfer-compression" onclick="onNavClick(`#transfer-compression-nav`)" id="transfer-compression-nav">
									Transfer Compression
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#quick-udp-internet-connections" onclick="onNavClick(`#quick-udp-internet-connections-nav`)" id="quick-udp-internet-connections-nav">
									Quick UDP Internet Connections
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#content-distribution-network" onclick="onNavClick(`#content-distribution-network-nav`)" id="content-distribution-network-nav">
									Content Distribution Network
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#route-resolution" onclick="onNavClick(`#route-resolution-nav`)" id="route-resolution-nav">
									Route Resolution
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#content-distribution" onclick="onNavClick(`#content-distribution-nav`)" id="content-distribution-nav">
									Content Distribution
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cdn-applications" onclick="onNavClick(`#cdn-applications-nav`)" id="cdn-applications-nav">
									CDN Applications
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#load-balancing" onclick="onNavClick(`#load-balancing-nav`)" id="load-balancing-nav">
									Load Balancing
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#data-link-layer" onclick="onNavClick(`#data-link-layer-nav`)" id="data-link-layer-nav">
									Data Link Layer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#network-layer" onclick="onNavClick(`#network-layer-nav`)" id="network-layer-nav">
									Network Layer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#application-layer" onclick="onNavClick(`#application-layer-nav`)" id="application-layer-nav">
									Application Layer
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#balance-strategy" onclick="onNavClick(`#balance-strategy-nav`)" id="balance-strategy-nav">
									Balance Strategy
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#cache" onclick="onNavClick(`#cache-nav`)" id="cache-nav">
									Cache
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#properties" onclick="onNavClick(`#properties-nav`)" id="properties-nav">
									Properties
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#throughput" onclick="onNavClick(`#throughput-nav`)" id="throughput-nav">
									Throughput
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#hit-rate--elimination-strategy" onclick="onNavClick(`#hit-rate--elimination-strategy-nav`)" id="hit-rate--elimination-strategy-nav">
									Hit rate &amp; Elimination Strategy
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#extended-functionality" onclick="onNavClick(`#extended-functionality-nav`)" id="extended-functionality-nav">
									Extended functionality
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#distributed-support" onclick="onNavClick(`#distributed-support-nav`)" id="distributed-support-nav">
									Distributed support
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
						
						
						
							<li>
								<a href="#risks" onclick="onNavClick(`#risks-nav`)" id="risks-nav">
									Risks
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
							
								
									<ul>
								
							
						
						
							<li>
								<a href="#cache-penetration" onclick="onNavClick(`#cache-penetration-nav`)" id="cache-penetration-nav">
									Cache Penetration
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cache-breakdown" onclick="onNavClick(`#cache-breakdown-nav`)" id="cache-breakdown-nav">
									Cache Breakdown
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cache-avalanche" onclick="onNavClick(`#cache-avalanche-nav`)" id="cache-avalanche-nav">
									Cache Avalanche
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
						
						
							<li>
								<a href="#cache-pollution" onclick="onNavClick(`#cache-pollution-nav`)" id="cache-pollution-nav">
									Cache Pollution
								</a>
							</li>
						
						
					
				
			
				
				
					
						
						
						
							
								</ul>
							
								</ul>
							
						
						
						
							<li>
								<a href="#reference" onclick="onNavClick(`#reference-nav`)" id="reference-nav">
									Reference
								</a>
							</li>
						
						
					
				
			
		</ul>
	</div>

</div>
            
        </div>
    </div>
</div>
<transition name="fade">
    <div id="drawer-mask" v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if="isDrawerOpen" v-on:click="toggleDrawer"></div>
</transition>
<nav id="navBar" class="navbar sticky-top navbar-light single-column-nav-container">
    <div id="navBackground" class="nav-background"></div>
    <div class="container container-narrow nav-content">
        <button id="nav_dropdown_btn" class="nav-dropdown-toggle" type="button" v-on:click="toggleDrawer">
            <i class="material-icons">
                menu
            </i>
        </button>
        <a id="navTitle" class="navbar-brand" href="https://www.openheart.icu/">
            42th openheart
        </a>
        
        <button type="button" class="nav-darkmode-toggle" id="darkModeToggleButton2">
            <i class="material-icons" id="darkModeToggleIcon2">
                dark_mode
            </i>
        </button>
        
    </div>
</nav>
<div class="single-column-header-container" id="pageHead"
     v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }">
    <a href="https://www.openheart.icu/">
        <div class="single-column-header-title">42th openheart</div>
        
        <div class="single-column-header-subtitle">Kris Nie&#39;s Blog.</div>
        

    </a>
</div>

            <div id="content">
                <div id="streamContainer" class="stream-container">

    <div class="post-list-container post-list-container-shadow">
        <div class="post">
            
            
            

            <div class="post-head-wrapper-text-only"
                
            >
                <div class="post-title">
                    Transparent Multilevel Diversion
                    
                    <div class="post-subtitle">
                        透明多级分流
                    </div>
                    
                    <div class="post-meta">
                        
                        <time itemprop="datePublished">
                            2021-12-01 14:28
                        </time>
                        

                        
                            <i class="material-icons" style="">folder</i>
                                <a href="/categories/technical">Technical</a>
                                &nbsp;
                        

                        
                            <i class="material-icons" style="">label</i>
                            
                                <a href="/tags/cs">CS</a>
                                &nbsp;
                            
                        
                        
                            <i class="material-icons" style="">schedule</i>
                            

                            
                            

                            
                            109 min
                            
                            58 s.
                        
                    </div>
                </div>
            </div>
            
            <div class="post-body-wrapper">
                
                <div class="post-body" v-pre>
                
                    <p>在用户使用信息系统的过程中，请求从浏览器出发，在域名服务器的指引下找到系统的入口，经过网关、负载均衡器、缓存、服务集群等一系列设施，最后触及到末端存储于数据库服务器中的信息，然后逐级返回到用户的浏览器之中。这其中要经过很多技术部件：</p>
<ul>
<li>有一些部件位于客户端或网络的边缘，能够迅速响应用户的请求，避免给后方的 I/O 与 CPU 带来压力，典型如本地缓存、内容分发网络、反向代理等。</li>
<li>有一些部件的处理能力能够线性拓展，易于伸缩，可以使用较小的代价堆叠机器来获得与用户数量相匹配的并发性能，应尽量作为业务逻辑的主要载体，典型如集群中能够自动扩缩的服务节点。</li>
<li>有一些部件稳定服务对系统运行有全局性的影响，要时刻保持着容错备份，维护着高可用性，典型如服务注册中心、配置中心。</li>
<li>有一些设施是天生的单点部件，只能依靠升级机器本身的网络、存储和运算性能来提升处理能力，如位于系统入口的路由、网关或者负载均衡器（它们都可以做集群，但一次网络请求中无可避免至少有一个是单点的部件）、位于请求调用链末端的传统关系数据库等，都是典型的容易形成单点部件。</li>
</ul>
<p>对系统进行流量规划时，我们应该充分理解这些部件的价值差异，有两条简单、普适的原则能指导我们进行设计：</p>
<ul>
<li>第一条原则是尽可能减少单点部件，如果某些单点是无可避免的，则应尽最大限度减少到达单点部件的流量。在系统中往往会有多个部件能够处理、响应用户请求，譬如要获取一张存储在数据库的用户头像图片，浏览器缓存、内容分发网络、反向代理、Web 服务器、文件服务器、数据库都可能提供这张图片。恰如其分地引导请求分流至最合适的组件中，避免绝大多数流量汇集到单点部件（如数据库），同时依然能够在绝大多数时候保证处理结果的准确性，使单点系统在出现故障时自动而迅速地实施补救措施，这便是系统架构中多级分流的意义。</li>
<li>另一条更关键的原则是<a href="https://en.wikipedia.org/wiki/Occam%27s_razor">奥卡姆剃刀原则</a>。作为一名架构设计者，你应对多级分流的手段有全面的理解与充分的准备，同时清晰地意识到这些设施并不是越多越好。在实际构建系统时，你应当在有明确需求、真正必要的时候再去考虑部署它们。不是每一个系统都要追求高并发、高可用的，根据系统的用户量、峰值流量和团队本身的技术与运维能力来考虑如何部署这些设施才是合理的做法，在能满足需求的前提下，<strong>最简单的系统就是最好的系统</strong>。</li>
</ul>
<h1 id="client-cache">Client Cache</h1>
<h2 id="force-caching">Force Caching</h2>
<p>假设在某个时点到来以前，譬如收到响应后的 10 分钟内，资源的内容和状态一定不会被改变，因此客户端可以无须经过任何请求，在该时点前一直持有和使用该资源的本地缓存副本。</p>
<p>根据约定，强制缓存在浏览器的地址输入、页面链接跳转、新开窗口、前进和后退中均可生效，但在用户主动刷新页面时应当自动失效。</p>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Expires">Expires</a>
<ul>
<li>受限于客户端的本地时间。</li>
<li>无法处理涉及到用户身份的私有资源，譬如，某些资源被登录用户缓存在自己的浏览器上是合理的，但如果被代理服务器或者内容分发网络缓存起来，则可能被其他未认证的用户所获取。</li>
<li>无法描述“不缓存”的语义。譬如，浏览器为了提高性能，往往会自动在当次会话中缓存某些 MIME 类型的资源，在 HTTP/1.0 的服务器中就缺乏手段强制浏览器不允许缓存某个资源。以前为了实现这类功能，通常不得不使用脚本，或者手工在资源后面增加时间戳（譬如如“xx.js?t=1586359920”、“xx.jpg?t=1586359350”）来保证每次资源都会重新获取。
关于“不缓存”的语义，在 HTTP/1.0 中其实预留了“Pragma: no-cache”来表达，但 Pragma 参数在 HTTP/1.0 中并没有确切描述其具体行为，随后就被 HTTP/1.1 中出现过的 Cache-Control 所替代，现在，尽管主流浏览器通常都会支持 Pragma，但行为仍然是不确定的，实际并没有什么使用价值。</li>
</ul>
</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control">Cache-Control</a></li>
</ul>
<h2 id="negotiate-caching">Negotiate Caching</h2>
<p>强制缓存是基于时效性的，但无论是人还是服务器，其实多数情况下都并没有什么把握去承诺某项资源多久不会发生变化。</p>
<p>根据约定，协商缓存不仅在浏览器的地址输入、页面链接跳转、新开窗口、前进、后退中生效，而且在用户主动刷新页面（F5）时也同样是生效的，只有用户强制刷新（Ctrl+F5）或者明确禁用缓存（譬如在 DevTools 中设定）时才会失效，此时客户端向服务端发出的请求会自动带有“Cache-Control: no-cache”。</p>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Last-Modified">Last-Modified</a> &amp; <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/If-Modified-Since">If-Modified-Since</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETag</a> &amp; <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/If-None-Match">If-None-Match</a></li>
</ul>
<p>Etag 是 HTTP 中一致性最强的缓存机制，譬如，Last-Modified 标注的最后修改只能精确到秒级，如果某些文件在 1 秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间；又或者如果某些文件会被定期生成，可能内容并没有任何变化，但 Last-Modified 却改变了，导致文件无法有效使用缓存，这些情况 Last-Modified 都有可能产生资源一致性问题，只能使用 Etag 解决。</p>
<p>Etag 却又是 HTTP 中性能最差的缓存机制，体现在每次请求时，服务端都必须对资源进行哈希计算，这比起简单获取一下修改时间，开销要大了很多。Etag 和 Last-Modified 是允许一起使用的，服务器会优先验证 Etag，在 Etag 一致的情况下，再去对比 Last-Modified，这是为了防止有一些 HTTP 服务器未将文件修改日期纳入哈希范围内。</p>
<h1 id="dns-lookup">DNS Lookup</h1>
<p>首先 DNS 会将域名还原为“<code>www.google.com.cn.</code>”，注意最后多了一个点“<code>.</code>”，它是“<code>.root</code>”的含义。</p>
<ol>
<li>客户端先检查本地的 DNS 缓存，查看是否存在并且是存活着的该域名的地址记录。DNS 是以<a href="https://en.wikipedia.org/wiki/Time_to_live">存活时间</a>（Time to Live，TTL）来衡量缓存的有效情况的，所以，如果某个域名改变了 IP 地址，DNS 服务器并没有任何机制去通知缓存了该地址的机器去更新或者失效掉缓存，只能依靠 TTL 超期后的重新获取来保证一致性。后续每一级 DNS 查询的过程都会有类似的缓存查询操作。</li>
<li>客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS），这个本地 DNS 服务器可以由用户手工设置，也可以在 DHCP 分配时或者在拨号时从 PPP 服务器中自动获取到。</li>
<li>本地 DNS 收到查询请求后，会按照“是否有<code>www.google.com.cn</code>的权威服务器”→“是否有<code>google.com.cn</code>的权威服务器”→“是否有<code>com.cn</code>的权威服务器”→“是否有<code>cn</code>的权威服务器”的顺序，依次查询自己的地址记录，如果都没有查询到，就会一直找到最后点号代表的根域名服务器为止。这个步骤里涉及了两个重要名词：
<ul>
<li><strong>权威域名服务器</strong>（Authoritative DNS）：是指负责翻译特定域名的 DNS 服务器，“权威”意味着这个域名应该翻译出怎样的结果是由它来决定的。DNS 翻译域名时无需像查电话本一样刻板地一对一翻译，根据来访机器、网络链路、服务内容等各种信息，可以玩出很多花样，权威 DNS 的灵活应用，在后面的内容分发网络、服务发现等章节都还会有所涉及。</li>
<li><strong>根域名服务器</strong>（Root DNS）是指固定的、无需查询的<a href="https://en.wikipedia.org/wiki/Top-level_domain">顶级域名</a>（Top-Level Domain）服务器，可以默认为它们已内置在操作系统代码之中。全世界一共有 13 组根域名服务器（注意并不是 13 台，每一组根域名都通过<a href="https://en.wikipedia.org/wiki/Anycast">任播</a>的方式建立了一大群镜像，根据维基百科的数据，迄今已经超过 1000 台根域名服务器的镜像了）。13 这个数字是由于 DNS 主要采用 UDP 传输协议（在需要稳定性保证的时候也可以采用 TCP）来进行数据交换，未分片的 UDP 数据包在 IPv4 下最大有效值为 512 字节，最多可以存放 13 组地址记录，由此而来的限制。</li>
</ul>
</li>
<li>现在假设本地 DNS 是全新的，上面不存在任何域名的权威服务器记录，所以当 DNS 查询请求按步骤 3 的顺序一直查到根域名服务器之后，它将会得到“<code>cn</code>的权威服务器”的地址记录，然后通过“<code>cn</code>的权威服务器”，得到“<code>com.cn</code>的权威服务器”的地址记录，以此类推，最后找到能够解释<code>www.google.com.cn</code>的权威服务器地址。</li>
<li>通过“<code>www.google.com.cn</code>的权威服务器”，查询<code>www.google.com.cn</code>的地址记录，地址记录并不一定就是指 IP 地址，在 RFC 规范中有定义的地址记录类型已经<a href="https://en.wikipedia.org/wiki/List_of_DNS_record_types">多达数十种</a>，譬如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。</li>
</ol>
<p>DNS 系统多级分流的设计使得 DNS 系统能够经受住全球网络流量不间断的冲击，但也并非全无缺点。典型的问题是响应速度，当极端情况（各级服务器均无缓存）下的域名解析可能导致每个域名都必须递归多次才能查询到结果，显著影响传输的响应速度。专门有一种被称为“<a href="https://en.wikipedia.org/wiki/Link_prefetching">DNS 预取</a>”（DNS Prefetching）的前端优化手段用来避免这类问题：如果网站后续要使用来自于其他域的资源，那就在网页加载时生成一个 link 请求，促使浏览器提前对该域名进行预解释</p>
<div class="highlight"><pre style="background-color:#eed;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-html" data-lang="html">&lt;<span style="color:#8b008b;font-weight:bold">link</span> <span style="color:#658b00">rel</span>=<span style="color:#cd5555">&#34;dns-prefetch&#34;</span> <span style="color:#658b00">href</span>=<span style="color:#cd5555">&#34;//domain.not-icyfenx.cn&#34;</span>&gt;
</code></pre></div><p>而另一种可能更严重的缺陷是 DNS 的分级查询意味着每一级都有可能受到中间人攻击的威胁，产生被劫持的风险。要攻陷位于递归链条顶层的（譬如根域名服务器，cn 权威服务器）服务器和链路是非常困难的，它们都有很专业的安全防护措施。但很多位于递归链底层或者来自本地运营商的 Local DNS 服务器的安全防护则相对松懈，甚至不少地区的运营商自己就会主动进行劫持，专门返回一个错的 IP，通过在这个 IP 上代理用户请求，以便给特定类型的资源（主要是 HTML）注入广告，以此牟利。</p>
<p>为此，最近几年出现了另一种新的 DNS 工作模式：<a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS">HTTPDNS</a>（也称为 DNS over HTTPS，DoH）。它将原本的 DNS 解析服务开放为一个基于 HTTPS 协议的查询服务，替代基于 UDP 传输协议的 DNS 域名解析，通过程序代替操作系统直接从权威 DNS 或者可靠的 Local DNS 获取解析数据，从而绕过传统 Local DNS。这种做法的好处是完全免去了“中间商赚差价”的环节，不再惧怕底层的域名劫持，能够有效避免 Local DNS 不可靠导致的域名生效缓慢、来源 IP 不准确、产生的智能线路切换错误等问题。</p>
<h1 id="transmission-optimization">Transmission Optimization</h1>
<p>程序发出的请求能否与应用层、传输层协议提倡的方式相匹配，对传输的效率也会有极大影响。优化链路传输为目的的前端设计不少，譬如经典的<a href="https://developer.yahoo.com/performance/rules.html">雅虎 YSlow-23 条规则</a>中与传输相关的内容如下。</p>
<ol>
<li>
<p>Minimize HTTP Requests。</p>
<p>减少请求数量：请求每次都需要建立通信链路进行数据传输，这些开销很昂贵，减少请求的数量可有效的提高访问性能，对于前端开发者，可能用来减少请求数量的手段包括：</p>
<ul>
<li>雪碧图（<a href="https://en.wikipedia.org/w/index.php?title=CSS_Sprites&amp;redirect=no">CSS Sprites</a>）</li>
<li>CSS、JS 文件合并/内联（Concatenation / Inline）</li>
<li>分段文档（<a href="https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html">Multipart Document</a>）</li>
<li>媒体（图片、音频）内联（<a href="https://en.wikipedia.org/wiki/Data_URI_scheme">Data Base64 URI</a>）</li>
<li>合并 Ajax 请求（Batch Ajax Request）</li>
<li>……</li>
</ul>
</li>
<li>
<p>Split Components Across Domains。
扩大并发请求数：现代浏览器（Chrome、Firefox）一般对每个域名支持 6 个（IE 为 8-13 个）并发请求，如果希望更快地加载大量图片或其他资源，需要进行域名分片（Domain Sharding），将图片同步到不同主机或者同一个主机的不同域名上。</p>
</li>
<li>
<p>GZip Components。
启用压缩传输：启用压缩能够大幅度减少需要在网络上传输内容的大小，节省网络流量。</p>
</li>
<li>
<p>Avoid Redirects。
避免页面重定向：当页面发生了重定向，就会延迟整个文档的传输。在 HTML 文档到达之前，页面中不会呈现任何东西，降低了用户体验。</p>
</li>
<li>
<p>Put Stylesheets at the Top，Put Scripts at the Bottom。
按重要性调节资源优先级：将重要的、马上就要使用的、对客户端展示影响大的资源，放在 HTML 的头部，以便优先下载。</p>
</li>
<li>
<p>…………</p>
</li>
</ol>
<h2 id="optimization-of-connections-number">Optimization of Connections' Number</h2>
<p>TCP 协议要求必须在<a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Connection_establishment">三次握手</a>完成之后才能开始数据传输，这是一个可能高达“百毫秒”为计时尺度的事件；另外，TCP 还有<a href="https://en.wikipedia.org/wiki/TCP_congestion_control#Slow_start">慢启动</a>的特性，使得刚刚建立连接时传输速度是最低的，后面再逐步加速直至稳定。由于 TCP 协议本身是面向于长时间、大数据传输来设计的，在长时间尺度下，它连接建立的高昂成本才不至于成为瓶颈，它的稳定性和可靠性的优势才能展现出来。因此，可以说 HTTP over TCP 这种搭配在目标特征上确实是有矛盾的，以至于 HTTP/1.x 时代，大量短而小的 TCP 连接导致了网络性能的瓶颈。为了缓解 HTTP 与 TCP 之间的矛盾，聪明的程序员们一面致力于减少发出的请求数量，另外一方面也致力于增加客户端到服务端的连接数量，这就是上面 Yslow 规则中“Minimize HTTP Requests”与“Split Components Across Domains”两条优化措施的根本依据所在。</p>
<p>通过前端开发者的各种 Tricks，的确能够减少消耗 TCP 连接数量。但是，通过开发人员的 Tricks 来节省 TCP 连接，这样的优化措施并非只有好处，它们同时也带来了诸多不良的副作用：</p>
<ul>
<li>如果你用 CSS Sprites 将多张图片合并，意味着任何场景下哪怕只用到其中一张小图，也必须完整加载整个大图片；任何场景下哪怕一张小图要进行修改，都会导致整个缓存失效，类似地，样式、脚本等其他文件的合并也会造成同样的问题。</li>
<li>如果你使用了媒体内嵌，除了要承受 Base64 编码导致传输容量膨胀 1/3 的代价外（Base64 以 8 bit 表示 6 bit 数据），也将无法有效利用缓存。</li>
<li>如果你合并了异步请求，这就会导致所有请求返回时间都受最慢的那个请求的拖累，整体响应速度下降.</li>
<li>如果你把图片放到不同子域下面，将会导致更大的 DNS 解析负担，而且浏览器对两个不同子域下的同一图片必须持有两份缓存，也使得缓存效率的下降。</li>
<li>……</li>
</ul>
<p>HTTP 协议的最初版本（指 HTTP/1.0，忽略非正式的 HTTP/0.9 版本）就已经支持了连接复用技术（连接复用技术在 HTTP/1.0 中并不是默认开启的，是在 HTTP/1.1 中变为默认开启），即今天大家所熟知的<a href="https://en.wikipedia.org/wiki/HTTP_persistent_connection">持久连接</a>（Persistent Connection），也称为连接<a href="https://en.wikipedia.org/wiki/Keepalive">Keep-Alive 机制</a>。持久连接的原理是让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接。典型做法是在客户端维护一个 FIFO 队列，每次取完数据（如何在不断开连接下判断取完数据将会放到稍后<a href="http://icyfenix.cn/architect-perspective/general-architecture/diversion-system/transmission-optimization.html#%E4%BC%A0%E8%BE%93%E5%8E%8B%E7%BC%A9">传输压缩</a>部分去讨论）之后一段时间内不自动断开连接，以便获取下一个资源时直接复用，避免创建 TCP 连接的成本。</p>
<p>但是，连接复用技术依然是不完美的，最明显的副作用是“<a href="https://en.wikipedia.org/wiki/Head-of-line_blocking">队首阻塞</a>”（Head-of-Line Blocking）。队首阻塞问题一直持续到第二代的 HTTP 协议，即 HTTP/2 发布后才算是被比较完美地解决。在 HTTP/1.x 中，HTTP 请求就是传输过程中最小粒度的信息单位了，所以如果将多个请求切碎，再混杂在一块传输，客户端势必难以分辨重组出有效信息。而在 HTTP/2 中，帧（Frame）才是最小粒度的信息单位，它可以用来描述各种数据，譬如请求的 Headers、Body，或者用来做控制标识，譬如打开流、关闭流。这里说的流（Stream）是一个逻辑上的数据通道概念，每个帧都附带一个流 ID 以标识这个帧属于哪个流。这样，在同一个 TCP 连接中传输的多个数据帧就可以根据流 ID 轻易区分出开来，在客户端毫不费力地将不同流中的数据重组出不同 HTTP 请求和响应报文来。这项设计是 HTTP/2 的最重要的技术特征一，被称为 HTTP/2 <a href="https://tools.ietf.org/html/rfc7540#page-15">多路复用</a>（HTTP/2 Multiplexing）技术，如图 所示。</p>
<p><img src="http://icyfenix.cn/assets/img/http2-con.f8b394df.png" alt="img"></p>
<p>有了多路复用的支持，HTTP/2 就可以对每个域名只维持一个 TCP 连接（One Connection Per Origin）来以任意顺序传输任意数量的资源，既减轻了服务器的连接压力，开发者也不用去考虑域名分片这种事情来突破浏览器对每个域名最多 6 个连接数限制了。而更重要的是，没有了 TCP 连接数的压力，就无须刻意压缩 HTTP 请求了，所有通过合并、内联文件（无论是图片、样式、脚本）以减少请求数的需求都不再成立，甚至反而是徒增副作用的反模式。</p>
<p>必须先承认一个事实，在 HTTP 传输中 Headers 占传输成本的比重是相当的大，对于许多小资源，甚至可能出现 Headers 的容量比 Body 的还要大，以至于在 HTTP/2 中必须专门考虑如何进行 Header 压缩的问题。但是，以下几个因素决定了通过合并资源文件减少请求数，对节省 Headers 成本也并没有太大帮助：</p>
<ul>
<li>Header 的传输成本在 Ajax（尤其是只返回少量数据的请求）请求中可能是比重很大的开销，但在图片、样式、脚本这些静态资源的请求中，通常并不占主要。</li>
<li>在 HTTP/2 中 Header 压缩的原理是基于字典编码的信息复用，简而言之是同一个连接上产生的请求和响应越多，动态字典积累得越全，头部压缩效果也就越好。所以 HTTP/2 是单域名单连接的机制，合并资源和域名分片反而对性能提升不利。</li>
<li>与 HTTP/1.x 相反，HTTP/2 本身反而变得更适合传输小资源了，譬如传输 1000 张 10K 的小图，HTTP/2 要比 HTTP/1.x 快，但传输 10 张 1000K 的大图，则应该 HTTP/1.x 会更快。这一方面是 TCP 连接数量（相当于多点下载）的影响，更多的是由于 TCP 协议<a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Reliable_transmission">可靠传输机制</a>导致的，一个错误的 TCP 包会导致所有的流都必须等待这个包重传成功，这个问题就是 HTTP/3 要解决的目标了。因此，把小文件合并成大文件，在 HTTP/2 下是毫无好处的。</li>
</ul>
<h2 id="transfer-compression">Transfer Compression</h2>
<p>HTTP 很早就支持了<a href="https://en.wikipedia.org/wiki/Gzip">GZip</a>压缩，由于 HTTP 传输的主要内容，譬如 HTML、CSS、Script 等，主要是文本数据，对于文本数据启用压缩的收益是非常高的，传输数据量一般会降至原有的 20%左右。而对于那些不适合压缩的资源，Web 服务器则能根据 MIME 类型来自动判断是否对响应进行压缩，这样，已经采用过压缩算法存储的资源，如 JPEG、PNG 图片，便不会被二次压缩，空耗性能。</p>
<p>早期，服务器处理能力还很薄弱，为了启用压缩，会是把静态资源先预先压缩为.gz 文件的形式存放起来，当客户端可以接受压缩版本的资源时（请求的 Header 中包含 Accept-Encoding: gzip）就返回压缩后的版本（响应的 Header 中包含 Content-Encoding: gzip），否则就返回未压缩的原版，这种方式被称为“<a href="http://nginx.org/en/docs/http/ngx_http_gzip_static_module.html">静态预压缩</a>”（Static Precompression）。而现代的 Web 服务器处理能力有了大幅提升，已经没有人再采用麻烦的预压缩方式了，都是由服务器对符合条件的请求将在输出时进行“<a href="https://www.usenix.org/legacy/publications/library/proceedings/jvm01/full_papers/hovemeyer/hovemeyer_html/node7.html">即时压缩</a>”（On-The-Fly Compression），整个压缩过程全部在内存的数据流中完成，不必等资源压缩完成再返回响应，这样可以显著提高“<a href="https://en.wikipedia.org/wiki/Time_to_first_byte">首字节时间</a>”（Time To First Byte，TTFB），改善 Web 性能体验。而这个过程中唯一不好的地方就是服务器再也没有办法给出 Content-Length 这个响应 Header 了，因为输出 Header 时服务器还不知道压缩后资源的确切大小。</p>
<p>由于启用即时压缩后就无法给出 Content-Length 了，如果是 HTTP/1.0 的话，持久链接和即时压缩只能二选其一，事实上在 HTTP/1.0 中两者都支持，却默认都是不启用的。依靠 Content-Length 来判断传输结束的缺陷，不仅仅在于即时压缩这一种场景，譬如对于动态内容（Ajax、PHP、JSP 等输出），服务器也同样无法事项得知 Content-Length。</p>
<p>HTTP/1.1 版本中修复了这个缺陷，增加了另一种“<a href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding">分块传输编码</a>”（Chunked Transfer Encoding）的资源结束判断机制，彻底解决了 Content-Length 与持久链接的冲突问题。分块编码原理相当简单：在响应 Header 中加入“Transfer-Encoding: chunked”之后，就代表这个响应报文将采用分块编码。此时，报文中的 Body 需要改为用一系列“分块”来传输。每个分块包含十六进制的长度值和对应长度的数据内容，长度值独占一行，数据从下一行开始。最后以一个长度值为 0 的分块来表示资源结束。</p>
<h2 id="quick-udp-internet-connections">Quick UDP Internet Connections</h2>
<p><a href="https://en.wikipedia.org/wiki/QUIC">快速 UDP 网络连接</a>（Quick UDP Internet Connections，QUIC）会以 UDP 协议为基础，而 UDP 协议没有丢包自动重传的特性。的另一个设计目标是面向移动设备的专门支持，由于以前 TCP、UDP 传输协议在设计时根本不可能设想到今天移动设备盛行的场景，因此肯定不会有任何专门的支持。QUIC 在移动设备上的优势体现在网络切换时的响应速度上，譬如当移动设备在不同 WiFi 热点之间切换，或者从 WiFi 切换到移动网络时，如果使用 TCP 协议，现存的所有连接都必定会超时、中断，然后根据需要重新创建。这个过程会带来很高的延迟，因为超时和重新握手都需要大量时间。为此，QUIC 提出了连接标识符的概念，该标识符可以唯一地标识客户端与服务器之间的连接，而无须依靠 IP 地址。这样，切换网络后，只需向服务端发送一个包含此标识符的数据包即可重用既有的连接，因为即使用户的 IP 地址发生变化，原始连接连接标识符依然是有效的。</p>
<h1 id="content-distribution-network">Content Distribution Network</h1>
<p>如果把某个互联网系统比喻为一家企业，那内容分发网络就是它遍布世界各地的分支销售机构，现在有客户要买一块 CPU，那么订机票飞到美国加州 Intel 总部肯定是不合适的，到本地电脑城找个装机铺才是通常的做法，在此场景中，内容分发网络就相当于电脑城里的本地经销商。</p>
<p>如果抛却其他影响服务质量的因素，仅从网络传输的角度看，一个互联网系统的速度取决于以下四点因素：</p>
<ol>
<li>网站服务器接入网络运营商的链路所能提供的出口带宽。</li>
<li>用户客户端接入网络运营商的链路所能提供的入口带宽。</li>
<li>从网站到用户之间经过的不同运营商之间互联节点的带宽，一般来说两个运营商之间只有固定的若干个点是互通的，所有跨运营商之间的交互都要经过这些点。</li>
<li>从网站到用户之间的物理链路传输时延。爱打游戏的同学应该都清楚，延迟（Ping 值）比带宽更重要。</li>
</ol>
<p>以上四个网络问题，除了第二个只能通过换一个更好的宽带才能解决之外，其余三个都能通过内容分发网络来显著改善。一个运作良好的内容分发网络，能为互联网系统解决跨运营商、跨地域物理距离所导致的时延问题，能为网站流量带宽起到分流、减负的作用。举个例子，如果不是有遍布全国乃至全世界的阿里云 CDN 网络支持，哪怕把整个杭州所有市民上网的权力都剥夺了，把带宽全部让给淘宝的机房，恐怕也撑不住全国乃至全球用户在双十一期间的疯狂“围殴”。</p>
<h2 id="route-resolution">Route Resolution</h2>
<p>路由解析过程：</p>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220214153530661.png" alt="image-20220214153530661"></p>
<p>CDN 路由解析的具体工作过程是：</p>
<ol>
<li>架设好“<code>icyfenix.cn</code>”的服务器后，将服务器的 IP 地址在你的 CDN 服务商上注册为“源站”，注册后你会得到一个 CNAME，即本例中的“<code>icyfenix.cn.cdn.dnsv1.com.</code>”。</li>
<li>将得到的 CNAME 在你购买域名的 DNS 服务商上注册为一条 CNAME 记录。</li>
<li>当第一位用户来访你的站点时，将首先发生一次未命中缓存的 DNS 查询，域名服务商解析出 CNAME 后，返回给本地 DNS，至此之后链路解析的主导权就开始由内容分发网络的调度服务接管了。</li>
<li>本地 DNS 查询 CNAME 时，由于能解析该 CNAME 的权威服务器只有 CDN 服务商所架设的权威 DNS，这个 DNS 服务将根据一定的均衡策略和参数，如拓扑结构、容量、时延等，在全国各地能提供服务的 CDN 缓存节点中挑选一个最适合的，将它的 IP 代替源站的 IP 地址，返回给本地 DNS。</li>
<li>浏览器从本地 DNS 拿到 IP 地址，将该 IP 当作源站服务器来进行访问，此时该 IP 的 CDN 节点上可能有，也可能没有缓存过源站的资源，这点将在稍后“<a href="http://icyfenix.cn/architect-perspective/general-architecture/diversion-system/cdn.html#%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91">内容分发</a>”小节讨论。</li>
<li>经过内容分发后的 CDN 节点，就有能力代替源站向用户提供所请求的资源。</li>
</ol>
<p>路由解析时序图：</p>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220214161418262.png" alt="image-20220214161418262"></p>
<h2 id="content-distribution">Content Distribution</h2>
<ul>
<li><strong>主动分发</strong>（Push）：分发由源站主动发起，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上。这个推送的操作没有什么业界标准可循，可以采用任何传输方式（HTTP、FTP、P2P，等等）、任何推送策略（满足特定条件、定时、人工，等等）、任何推送时间，只要与后面说的更新策略相匹配即可。由于主动分发通常需要源站、CDN 服务双方提供程序 API 接口层面的配合，所以它对源站并不是透明的，只对用户一侧单向透明。主动分发一般用于网站要预载大量资源的场景。譬如双十一之前一段时间内，淘宝、京东等各个网络商城就会开始把未来活动中所需用到的资源推送到 CDN 缓存节点中，特别常用的资源甚至会直接缓存到你的手机 APP 的存储空间或者浏览器的<a href="https://en.wikipedia.org/wiki/Web_storage#localStorage">localStorage</a>上。</li>
<li><strong>被动回源</strong>（Pull）：被动回源由用户访问所触发全自动、双向透明的资源缓存过程。当某个资源首次被用户请求的时候，CDN 缓存节点发现自己没有该资源，就会实时从源站中获取，这时资源的响应时间可粗略认为是资源从源站到 CDN 缓存节点的时间，再加上资源从 CDN 发送到用户的时间之和。因此，被动回源的首次访问通常是比较慢的（但由于 CDN 的网络条件一般远高于普通用户，并不一定就会比用户直接访问源站更慢），不适合应用于数据量较大的资源。被动回源的优点是可以做到完全的双向透明，不需要源站在程序上做任何的配合，使用起来非常方便。这种分发方式是小型站点使用 CDN 服务的主流选择，如果不是自建 CDN，而是购买阿里云、腾讯云的 CDN 服务的站点，多数采用的就是这种方式。</li>
</ul>
<h2 id="cdn-applications">CDN Applications</h2>
<ul>
<li>加速静态资源：这是 CDN 本职工作。</li>
<li>安全防御：CDN 在广义上可以视作网站的堡垒机，源站只对 CDN 提供服务，由 CDN 来对外界其他用户服务，这样恶意攻击者就不容易直接威胁源站。CDN 对某些攻击手段的防御，如对<a href="https://zh.wikipedia.org/zh-tw/%E9%98%BB%E6%96%B7%E6%9C%8D%E5%8B%99%E6%94%BB%E6%93%8A">DDoS 攻击</a>的防御尤其有效。但需注意，将安全都寄托在 CDN 上本身是不安全的，一旦源站真实 IP 被泄漏，就会面临很高的风险。</li>
<li>协议升级：不少 CDN 提供商都同时对接（代售 CA 的）SSL 证书服务，可以实现源站是 HTTP 协议的，而对外开放的网站是基于 HTTPS 的。同理，可以实现源站到 CDN 是 HTTP/1.x 协议，CDN 提供的外部服务是 HTTP/2 或 HTTP/3 协议、实现源站是基于 IPv4 网络的，CDN 提供的外部服务支持 IPv6 网络，等等。</li>
<li>状态缓存：第一节介绍客户端缓存时简要提到了状态缓存，CDN 不仅可以缓存源站的资源，还可以缓存源站的状态，譬如源站的 301/302 转向就可以缓存起来让客户端直接跳转、还可以通过 CDN 开启<a href="https://es.wikipedia.org/wiki/HTTP_Strict_Transport_Security">HSTS</a>、可以通过 CDN 进行<a href="https://zh.wikipedia.org/wiki/OCSP%E8%A3%85%E8%AE%A2">OCSP 装订</a>加速 SSL 证书访问，等等。有一些情况下甚至可以配置 CDN 对任意状态码（譬如 404）进行一定时间的缓存，以减轻源站压力，但这个操作应当慎重，在网站状态发生改变时去及时刷新缓存。</li>
<li>修改资源：CDN 可以在返回资源给用户的时候修改它的任何内容，以实现不同的目的。譬如，可以对源站未压缩的资源自动压缩并修改 Content-Encoding，以节省用户的网络带宽消耗、可以对源站未启用客户端缓存的内容加上缓存 Header，自动启用客户端缓存，可以修改<a href="https://developer.mozilla.org/zh-CN/docs/Glossary/CORS">CORS</a>的相关 Header，将源站不支持跨域的资源提供跨域能力，等等。</li>
<li>访问控制：CDN 可以实现 IP 黑/白名单功能，根据不同的来访 IP 提供不同的响应结果，根据 IP 的访问流量来实现 QoS 控制、根据 HTTP 的 Referer 来实现防盗链，等等。</li>
<li>注入功能：CDN 可以在不修改源站代码的前提下，为源站注入各种功能，比如国际 CDN 巨头 CloudFlare 提供的 Google Analytics、PACE、Hardenize 等第三方应用，在 CDN 下均能做到无须修改源站任何代码即可使用。</li>
<li>绕过某些“不存在的”网络措施，这也是在国内申请 CDN 也必须实名备案的原因，就不细说了。</li>
</ul>
<h1 id="load-balancing">Load Balancing</h1>
<p>在互联网时代的早期，网站流量还相对较小，并且业务也比较简单，单台服务器便有可能满足访问需要，但时至今日，互联网应用也好，企业级应用也好，一般实际用于生产的系统，几乎都离不开集群部署了。信息系统不论是采用单体架构多副本部署还是微服务架构，不论是为了实现高可用还是为了获得高性能，都需要利用到多台机器来扩展服务能力，希望用户的请求不管连接到哪台机器上，都能得到相同的处理。另一方面，如何构建和调度服务集群这事情，又必须对用户一侧保持足够的透明，即使请求背后是由一千台、一万台机器来共同响应的，也绝非用户所关心的事情，用户需记住的只有一个域名地址而已。调度后方的多台机器，以统一的接口对外提供服务，承担此职责的技术组件被称为“负载均衡”（Load Balancing）。</p>
<p>真正大型系统的负载均衡过程往往是多级的。譬如，在各地建有多个机房，或机房有不同网络链路入口的大型互联网站，会从 DNS 解析开始，通过“域名” → “CNAME” → “负载调度服务” → “就近的数据中心入口”的路径，先将来访地用户根据 IP 地址（或者其他条件）分配到一个合适的数据中心中，然后才到稍后将要讨论的各式负载均衡。在 DNS 层面的负载均衡与前面介绍的 DNS 智能线路、内容分发网络等，在工作原理上是类似的，其差别只是数据中心能提供的不仅有缓存，而是全方位的服务能力。由于这种方式此前已经详细讲解过，后续我们所讨论的“负载均衡”就只聚焦于网络请求进入数据中心入口之后的其他级次的负载均衡。</p>
<p>无论在网关内部建立了多少级的负载均衡，从形式上来说都可以分为两种：四层负载均衡和七层负载均衡。四层负载均衡的优势是性能高，七层负载均衡的优势是功能强。做多级混合负载均衡，通常应是低层的负载均衡在前，高层的负载均衡在后。</p>
<p>我们所说的“四层”、“七层”，指的是经典的<a href="https://en.wikipedia.org/wiki/OSI_model">OSI 七层模型</a>中第四层传输层和第七层应用层。</p>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220214164402864.png" alt="image-20220214164402864"></p>
<p>现在所说的“四层负载均衡”其实是多种均衡器工作模式的统称，“四层”的意思是说这些工作模式的共同特点是维持着同一个 TCP 连接，而不是说它只工作在第四层。事实上，这些模式主要都是工作在二层（数据链路层，改写 MAC 地址）和三层（网络层，改写 IP 地址）上，单纯只处理第四层（传输层，可以改写 TCP、UDP 等协议的内容和端口）的数据无法做到负载均衡的转发，因为 OSI 的下三层是媒体层（Media Layers），上四层是主机层（Host Layers），既然流量都已经到达目标主机上了，也就谈不上什么流量转发，最多只能做代理了。</p>
<h2 id="data-link-layer">Data Link Layer</h2>
<p>数据链路层传输的内容是数据帧（Frame），譬如常见的以太网帧、ADSL 宽带的 PPP 帧等。按照<a href="https://en.wikipedia.org/wiki/IEEE_802.3">IEEE 802.3</a>标准，最典型的 1500 Bytes MTU 的以太网帧结构如表所示：</p>
<table>
<thead>
<tr>
<th><strong>数据项</strong></th>
<th><strong>取值</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>前导码</td>
<td>10101010 7 Bytes</td>
</tr>
<tr>
<td>帧开始符</td>
<td>10101011 1 Byte</td>
</tr>
<tr>
<td>MAC 目标地址</td>
<td>6 Bytes</td>
</tr>
<tr>
<td>MAC 源地址</td>
<td>6 Bytes</td>
</tr>
<tr>
<td><a href="https://zh.wikipedia.org/wiki/IEEE_802.1Q">802.1Q</a>标签（可选）</td>
<td>4 Bytes</td>
</tr>
<tr>
<td><a href="https://zh.wikipedia.org/wiki/Ethertype">以太类型</a></td>
<td>2 Bytes</td>
</tr>
<tr>
<td>有效负载</td>
<td>1500 Bytes</td>
</tr>
<tr>
<td><a href="https://zh.wikipedia.org/wiki/%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">冗余校验</a></td>
<td>4 Bytes</td>
</tr>
<tr>
<td><a href="https://zh.wikipedia.org/w/index.php?title=%E5%B8%A7%E9%97%B4%E8%B7%9D&amp;action=edit&amp;redlink=1">帧间距</a></td>
<td>12 Bytes</td>
</tr>
</tbody>
</table>
<p>每一块网卡都有独立的 MAC 地址，以太帧上这“MAC 目标地址”和“MAC 源地址”告诉了交换机，此帧应该是从连接在交换机上的哪个端口的网卡发出，送至哪块网卡的。</p>
<p>数据链路层负载均衡所做的工作，是修改请求的数据帧中的 MAC 目标地址，让用户原本是发送给负载均衡器的请求的数据帧，被二层交换机根据新的 MAC 目标地址转发到服务器集群中对应的服务器（后文称为“真实服务器”，Real Server）的网卡上，这样真实服务器就获得了一个原本目标并不是发送给它的数据帧。</p>
<p>由于二层负载均衡器在转发请求过程中只修改了帧的 MAC 目标地址，不涉及更上层协议（没有修改 Payload 的数据），所以在更上层（第三层）看来，所有数据都是未曾被改变过的。由于第三层的数据包，即 IP 数据包中包含了源（客户端）和目标（均衡器）的 IP 地址，只有真实服务器保证自己的 IP 地址与数据包中的目标 IP 地址一致，这个数据包才能被正确处理。因此，使用这种负载均衡模式时，需要把真实物理服务器集群所有机器的<a href="https://en.wikipedia.org/wiki/Virtual_IP_address">虚拟 IP 地址</a>（Virtual IP Address，VIP）配置成与负载均衡器的虚拟 IP 一样，这样经均衡器转发后的数据包就能在真实服务器中顺利地使用。也正是因为实际处理请求的真实物理服务器 IP 和数据请求中的目的 IP 是一致的，所以响应结果就不再需要通过负载均衡服务器进行地址交换，可将响应结果的数据包直接从真实服务器返回给用户的客户端，避免负载均衡器网卡带宽成为瓶颈，因此数据链路层的负载均衡效率是相当高的。整个请求到响应的过程如图：</p>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220215135643227.png" alt="image-20220215135643227"></p>
<p>上述只有请求经过负载均衡器，而服务的响应无须从负载均衡器原路返回的工作模式，整个请求、转发、响应的链路形成一个“三角关系”，所以这种负载均衡模式也常被很形象地称为“三角传输模式”（Direct Server Return，DSR），也有叫“单臂模式”（Single Legged Mode）或者“直接路由”（Direct Routing）。</p>
<p>虽然数据链路层负载均衡效率很高，但它并不能适用于所有的场合，除了那些需要感知应用层协议信息的负载均衡场景它无法胜任外（所有的四层负载均衡器都无法胜任，将在后续介绍七层均衡器时一并解释），它在网络一侧受到的约束也很大。二层负载均衡器直接改写目标 MAC 地址的工作原理决定了<strong>它与真实的服务器的通信必须是二层可达的，通俗地说就是必须位于同一个子网当中，无法跨 VLAN</strong>。优势（效率高）和劣势（不能跨子网）共同决定了数据链路层负载均衡最适合用来做数据中心的第一级均衡设备，用来连接其他的下级负载均衡器。</p>
<h2 id="network-layer">Network Layer</h2>
<p>根据 OSI 七层模型，在第三层网络层传输的单位是分组数据包（Packets），这是一种在<a href="https://en.wikipedia.org/wiki/Packet_switching">分组交换网络</a>（Packet Switching Network，PSN）中传输的结构化数据单位。以 IP 协议为例，一个 IP 数据包由 Headers 和 Payload 两部分组成， Headers 长度最大为 60 Bytes，其中包括了 20 Bytes 的固定数据和最长不超过 40 Bytes 的可选的额外设置组成。按照 IPv4 标准，一个典型的分组数据包的 Headers 部分具有如表所示的结构：</p>
<table>
<thead>
<tr>
<th>长度</th>
<th>存储信息</th>
</tr>
</thead>
<tbody>
<tr>
<td>0-4 Bytes</td>
<td>版本号（4 Bits）、首部长度（4 Bits）、分区类型（8 Bits)、总长度（16 Bits）</td>
</tr>
<tr>
<td>5-8 Bytes</td>
<td>报文计数标识（16 Bits）、标志位（4 Bits）、片偏移（12 Bits）</td>
</tr>
<tr>
<td>9-12 Bytes</td>
<td>TTL 生存时间（8 Bits）、上层协议代号（8 Bits）、首部校验和（16 Bits）</td>
</tr>
<tr>
<td>13-16 Bytes</td>
<td>源地址（32 Bits）</td>
</tr>
<tr>
<td>17-20 Bytes</td>
<td>目标地址（32 Bits）</td>
</tr>
<tr>
<td>20-60 Bytes</td>
<td>可选字段和空白填充</td>
</tr>
</tbody>
</table>
<p>源和目标 IP 地址代表了数据是从分组交换网络中哪台机器发送到哪台机器的，我们可以沿用与二层改写 MAC 地址相似的思路，通过改变这里面的 IP 地址来实现数据包的转发。具体有两种常见的修改方式。</p>
<p>第一种是保持原来的数据包不变，新创建一个数据包，把原来数据包的 Headers 和 Payload 整体作为另一个新的数据包的 Payload，在这个新数据包的 Headers 中写入真实服务器的 IP 作为目标地址，然后把它发送出去。经过三层交换机的转发，真实服务器收到数据包后，必须在接收入口处设计一个针对性的拆包机制，把由负载均衡器自动添加的那层 Headers 扔掉，还原出原来的数据包来进行使用。这样，真实服务器就同样拿到了一个原本不是发给它（目标 IP 不是它）的数据包，达到了流量转发的目的。设计者给这种“套娃式”的传输起名叫做“<a href="https://en.wikipedia.org/wiki/IP_tunnel">IP 隧道</a>”（IP Tunnel）传输。</p>
<h2 id="application-layer">Application Layer</h2>
<p>转发，即直接将承载着 TCP 报文的底层数据格式（IP 数据包或以太网帧）转发到真实服务器上，此时客户端到响应请求的真实服务器维持着同一条 TCP 通道。工作在四层之后的负载均衡模式就无法再进行转发了，只能进行代理，此时真实服务器、负载均衡器、客户端三者之间由两条独立的 TCP 通道来维持通信。</p>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220322105920123.png" alt="image-20220322105920123"></p>
<ul>
<li>正向代理，指在客户端设置的、代表客户端与服务器通信的代理服务，它是客户端可知，而对服务器透明的。</li>
<li>反向代理，指在设置在服务器这一侧，代表真实服务器来与客户端通信的代理服务，此时它对客户端来说是透明的。</li>
<li>透明代理，指对双方都透明的，配置在网络中间设备上的代理服务，譬如，架设在路由器上的透明翻墙代理。</li>
</ul>
<p>所有 CDN 可以做的缓存方面的工作（就是除去 CDN 根据物理位置就近返回这种优化链路的工作外），七层均衡器全都可以实现，譬如静态资源缓存、协议升级、安全防护、访问控制，等等。</p>
<p>七层均衡器可以实现更智能化的路由。譬如，根据 Session 路由，以实现亲和性的集群；根据 URL 路由，实现专职化服务（此时就相当于网关的职责）；甚至根据用户身份路由，实现对部分用户的特殊服务（如某些站点的贵宾服务器），等等。</p>
<p>某些安全攻击可以由七层均衡器来抵御，譬如一种常见的 DDoS 手段是 SYN Flood 攻击，即攻击者控制众多客户端，使用虚假 IP 地址对同一目标大量发送 SYN 报文。从技术原理上看，由于四层均衡器无法感知上层协议的内容，这些 SYN 攻击都会被转发到后端的真实服务器上；而七层均衡器下这些 SYN 攻击自然在负载均衡设备上就被过滤掉，不会影响到后面服务器的正常运行。类似地，可以在七层均衡器上设定多种策略，譬如过滤特定报文，以防御如 SQL 注入等应用层面的特定攻击手段。</p>
<p>很多微服务架构的系统中，链路治理措施都需要在七层中进行，譬如服务降级、熔断、异常注入，等等。譬如，一台服务器只有出现物理层面或者系统层面的故障，导致无法应答 TCP 请求才能被四层均衡器所感知，进而剔除出服务集群，如果一台服务器能够应答，只是一直在报 500 错，那四层均衡器对此是完全无能为力的，只能由七层均衡器来解决。</p>
<h2 id="balance-strategy">Balance Strategy</h2>
<ul>
<li><strong>轮循均衡</strong>（Round Robin）：每一次来自网络的请求轮流分配给内部中的服务器，从 1 至 N 然后重新开始。此种均衡算法适合于集群中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。</li>
<li><strong>权重轮循均衡</strong>（Weighted Round Robin）：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。譬如：服务器 A 的权值被设计成 1，B 的权值是 3，C 的权值是 6，则服务器 A、B、C 将分别接收到 10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。</li>
<li><strong>随机均衡</strong>（Random）：把来自客户端的请求随机分配给内部中的多个服务器，在数据足够大的场景下能达到相对均衡的分布。</li>
<li><strong>权重随机均衡</strong>（Weighted Random）：此种均衡算法类似于权重轮循算法，不过在分配处理请求时是个随机选择的过程。</li>
<li><strong>一致性哈希均衡</strong>（Consistency Hash）：根据请求中某一些数据（可以是 MAC、IP 地址，也可以是更上层协议中的某些参数信息）作为特征值来计算需要落在的节点上，算法一般会保证同一个特征值每次都一定落在相同的服务器上。一致性的意思是保证当服务集群某个真实服务器出现故障，只影响该服务器的哈希，而不会导致整个服务集群的哈希键值重新分布。</li>
<li><strong>响应速度均衡</strong>（Response Time）：负载均衡设备对内部各服务器发出一个探测请求（例如 Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间。</li>
<li><strong>最少连接数均衡</strong>（Least Connection）：客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不平衡，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡策略适合长时处理的请求服务，如 FTP 传输。</li>
<li>…………</li>
</ul>
<p>从实现角度来看，负载均衡器的实现分为“软件均衡器”和“硬件均衡器”两类。在软件均衡器方面，又分为直接建设在操作系统内核的均衡器和应用程序形式的均衡器两种。前者的代表是 LVS（Linux Virtual Server），后者的代表有 Nginx、HAProxy、KeepAlived 等，前者性能会更好，因为无须在内核空间和应用空间中来回复制数据包；而后者的优势是选择广泛，使用方便，功能不受限于内核版本。</p>
<p>在硬件均衡器方面，往往会直接采用<a href="https://en.wikipedia.org/wiki/Application-specific_integrated_circuit">应用专用集成电路</a>（Application Specific Integrated Circuit，ASIC）来实现，有专用处理芯片的支持，避免操作系统层面的损耗，得以达到最高的性能。这类的代表就是著名的 F5 和 A10 公司的负载均衡产品。</p>
<h1 id="cache">Cache</h1>
<p>服务端缓存存在从开发角度来说，引入缓存会提高系统复杂度，因为你要考虑缓存的失效、更新、一致性等问题（硬件缓存也有这些问题，只是不需要由你去考虑，主流的 ISA (<a href="https://en.wikipedia.org/wiki/Instruction_set_architecture">Instruction Set Architecture</a>)也都没有提供任何直接操作缓存的指令）；从运维角度来说，缓存会掩盖掉一些缺陷，让问题在更久的时间以后，出现在距离发生现场更远的位置上；从安全角度来说，缓存可能泄漏某些保密数据，也是容易受到攻击的薄弱点。</p>
<p>引入缓存的关键理由：</p>
<ul>
<li>为缓解 CPU 压力而做缓存：譬如把方法运行结果存储起来、把原本要实时计算的内容提前算好、把一些公用的数据进行复用，这可以节省 CPU 算力，顺带提升响应性能。</li>
<li>为缓解 I/O 压力而做缓存：譬如把原本对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问，将原本对单点部件（如数据库）的读写访问变为到可扩缩部件（如缓存中间件）的访问，顺带提升响应性能。</li>
</ul>
<h2 id="properties">Properties</h2>
<h3 id="throughput">Throughput</h3>
<p>缓存的吞吐量使用 OPS 值（每秒操作数，Operations per Second，ops/s）来衡量，反映了对缓存进行<strong>并发</strong>读、写操作的效率，即缓存本身的工作效率高低。</p>
<p>不考虑并发的话，以 HashMap 或 Dictionary 实现的缓存，访问效率是常量时间复杂度，即 O(1)，但 HashMap 与 Dictionary 并不是线程安全的容器。</p>
<p>无论采用怎样的实现方法，线程安全措施都会带来一定的吞吐量损失。</p>
<p>在并发读写的场景中，吞吐量受多方面因素的共同影响，譬如，怎样设计数据结构以尽可能避免数据竞争，存在竞争风险时怎样处理同步（主要有使用锁实现的悲观同步和使用<a href="https://en.wikipedia.org/wiki/Compare-and-swap">CAS</a>实现的乐观同步）、如何避免<a href="https://en.wikipedia.org/wiki/False_sharing">伪共享现象</a>（False Sharing，这也算是典型缓存提升开发复杂度的例子）发生，等等。其中第一点尽可能避免竞争是最关键的，无论如何实现同步都不会比直接无须同步更快。</p>
<p>缓存中最主要的数据竞争源于读取数据的同时，也会伴随着对数据状态的写入操作，写入数据的同时，也会伴随着数据状态的读取操作。譬如，读取时要同时更新数据的最近访问时间和访问计数器的状态，以实现缓存的淘汰策略；又或者读取时要同时判断数据的超期时间等信息，以实现失效重加载等其他扩展功能。对以上伴随读写操作而来的状态维护，有两种可选择的处理思路，一种是以 Guava Cache 为代表的同步处理机制，即在访问数据时一并完成缓存淘汰、统计、失效等状态变更操作，通过分段加锁等优化手段来尽量减少竞争。另一种是以 Caffeine 为代表的异步日志提交机制，这种机制参考了经典的数据库设计理论，将对数据的读、写过程看作是日志（即对数据的操作指令）的提交过程。尽管日志也涉及到写入操作，有并发的数据变更就必然面临锁竞争，但异步提交的日志已经将原本在 Map 内的锁转移到日志的追加写操作上，日志里腾挪优化的余地就比在 Map 中要大得多。</p>
<p>在 Caffeine 的实现中，设有专门的<a href="https://en.wikipedia.org/wiki/Circular_buffer">环形缓存区</a>（Ring Buffer，也常称作 Circular Buffer）来记录由于数据读取而产生的状态变动日志。为进一步减少竞争，Caffeine 给每条线程（对线程取 Hash，哈希值相同的使用同一个缓冲区）都设置一个专用的环形缓冲。</p>
<blockquote>
<p>所谓环形缓冲，是一种拥有读、写两个指针的数据复用结构，在计算机科学中有非常广泛的应用。举个具体例子，譬如一台计算机通过键盘输入，并通过 CPU 读取“HELLO WIKIPEDIA”这个长 14 字节的单词，通常需要一个至少 14 字节以上的缓冲区才行。但如果是环形缓冲结构，读取和写入就应当一起进行，在读取指针之前的位置均可以重复使用，理想情况下，只要读取指针不落后于写入指针一整圈，这个缓冲区就可以持续工作下去，能容纳无限多个新字符。否则，就必须阻塞写入操作去等待读取清空缓冲区。</p>
<p><img src="http://icyfenix.cn/assets/img/Circular_Buffer_Animation.c3d3d834.gif" alt="img"></p>
<!-- raw HTML omitted -->
</blockquote>
<p>从 Caffeine 读取数据时，数据本身会在其内部的 ConcurrentHashMap 中直接返回，而数据的状态信息变更就存入环形缓冲中，由后台线程异步处理。如果异步处理的速度跟不上状态变更的速度，导致缓冲区满了，那此后接收的状态的变更信息就会直接被丢弃掉，直至缓冲区重新富余。通过环形缓冲和容忍有损失的状态变更，Caffeine 大幅降低了由于数据读取而导致的垃圾收集和锁竞争，因此 Caffeine 的读取性能几乎能与 ConcurrentHashMap 的读取性能相同。</p>
<p>向 Caffeine 写入数据时，将使用传统的有界队列（ArrayQueue）来存放状态变更信息，写入带来的状态变更是无损的，不允许丢失任何状态，这是考虑到许多状态的默认值必须通过写入操作来完成初始化，因此写入会有一定的性能损失。根据 Caffeine 官方给出的数据，相比 ConcurrentHashMap，Caffeine 在写入时大约会慢 10%左右。</p>
<h3 id="hit-rate--elimination-strategy">Hit rate &amp; Elimination Strategy</h3>
<p>缓存的命中率即成功从缓存中返回结果次数与总请求次数的比值，反映了引入缓存的价值高低，命中率越低，引入缓存的收益越小，价值越低。</p>
<p>有限的物理存储决定了任何缓存的容量都不可能是无限的，所以缓存需要在消耗空间与节约时间之间取得平衡，这要求缓存必须能够自动或者由人工淘汰掉缓存中的低价值数据，即缓存的淘汰策略，也常称作替换策略或者清理策略。</p>
<p>从缓存工作过程收集到的统计结果来确定数据是否有价值，通用的统计结果包括但不限于数据何时进入缓存、被使用过多少次、最近什么时候被使用，等等来确定缓存中的低价值数据。</p>
<p>目前，最基础的淘汰策略实现方案有以下三种：</p>
<ul>
<li><strong>FIFO</strong>（First In First Out）：优先淘汰最早进入被缓存的数据。FIFO 实现十分简单，但一般来说它并不是优秀的淘汰策略，越是频繁被用到的数据，往往会越早被存入缓存之中。如果采用这种淘汰策略，很可能会大幅降低缓存的命中率。</li>
<li><strong>LRU</strong>（Least Recent Used）：优先淘汰最久未被使用访问过的数据。LRU 通常会采用 HashMap 加 LinkedList 双重结构（如 LinkedHashMap）来实现，以 HashMap 来提供访问接口，保证常量时间复杂度的读取性能，以 LinkedList 的链表元素顺序来表示数据的时间顺序，每次缓存命中时把返回对象调整到 LinkedList 开头，每次缓存淘汰时从链表末端开始清理数据。对大多数的缓存场景来说，LRU 都明显要比 FIFO 策略合理，尤其适合用来处理短时间内频繁访问的热点对象。但相反，它的问题是如果一些热点数据在系统中经常被频繁访问，但最近一段时间因为某种原因未被访问过，此时这些热点数据依然要面临淘汰的命运，LRU 依然可能错误淘汰价值更高的数据。</li>
<li><strong>LFU</strong>（Least Frequently Used）：优先淘汰最不经常使用的数据。LFU 会给每个数据添加一个访问计数器，每访问一次就加 1，需要淘汰时就清理计数器数值最小的那批数据。LFU 可以解决上面 LRU 中热点数据间隔一段时间不访问就被淘汰的问题，但同时它又引入了两个新的问题，首先是需要对每个缓存的数据专门去维护一个计数器，每次访问都要更新，在上一节“吞吐量”里解释了这样做会带来高昂的维护开销；另一个问题是不便于处理随时间变化的热度变化，譬如某个曾经频繁访问的数据现在不需要了，它也很难自动被清理出缓存。</li>
</ul>
<p>此处的这三种策略其实与硬件中的缓存淘汰策略基本一致。不过，随着淘汰算法的发展，近年来的确出现了许多相对性能要更好的，也更为复杂的新算法。以 LFU 分支为例，针对它存在的两个问题，近年来提出的 TinyLFU 和 W-TinyLFU 算法就往往会有更好的效果。</p>
<ul>
<li><strong>TinyLFU</strong>（Tiny Least Frequently Used）：TinyLFU 是 LFU 的改进版本。为了缓解 LFU 每次访问都要修改计数器所带来的性能负担，TinyLFU 会首先采用 Sketch 对访问数据进行分析，所谓 Sketch 是统计学上的概念，指用少量的样本数据来估计全体数据的特征，这种做法显然牺牲了一定程度的准确性，但是只要样本数据与全体数据具有相同的概率分布，Sketch 得出的结论仍不失为一种高效与准确之间权衡的有效结论。借助<a href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch">Count–Min Sketch</a>算法（可视为<a href="https://en.wikipedia.org/wiki/Bloom_filter">布隆过滤器</a>的一种等价变种结构），TinyLFU 可以用相对小得多的记录频率和空间来近似地找出缓存中的低价值数据。为了解决 LFU 不便于处理随时间变化的热度变化问题，TinyLFU 采用了基于“滑动时间窗”（在“<a href="http://icyfenix.cn/distribution/traffic-management/traffic-control.html">流量控制</a>”中我们会更详细地分析这种算法）的热度衰减算法，简单理解就是每隔一段时间，便会把计数器的数值减半，以此解决“旧热点”数据难以清除的问题。</li>
<li><strong><a href="https://arxiv.org/pdf/1512.00727.pdf">W-TinyLFU</a></strong>（Windows-TinyLFU）：W-TinyLFU 又是 TinyLFU 的改进版本。TinyLFU 在实现减少计数器维护频率的同时，也带来了无法很好地应对稀疏突发访问的问题，所谓稀疏突发访问是指有一些绝对频率较小，但突发访问频率很高的数据，譬如某些运维性质的任务，也许一天、一周只会在特定时间运行一次，其余时间都不会用到，此时 TinyLFU 就很难让这类元素通过 Sketch 的过滤，因为它们无法在运行期间积累到足够高的频率。应对短时间的突发访问是 LRU 的强项，W-TinyLFU 就结合了 LRU 和 LFU 两者的优点，从整体上看是它是 LFU 策略，从局部实现上看又是 LRU 策略。具体做法是将新记录暂时放入一个名为 Window Cache 的前端 LRU 缓存里面，让这些对象可以在 Window Cache 中累积热度，如果能通过 TinyLFU 的过滤器，再进入名为 Main Cache 的主缓存中存储，主缓存根据数据的访问频繁程度分为不同的段（LFU 策略，实际上 W-TinyLFU 只分了两段），但单独某一段局部来看又是基于 LRU 策略去实现的（称为 Segmented LRU）。每当前一段缓存满了之后，会将低价值数据淘汰到后一段中去存储，直至最后一段也满了之后，该数据就彻底清理出缓存。</li>
</ul>
<p>Caffeine 官方给出的 W-TinyLFU 以及另外两种高级淘汰策略<a href="https://en.wikipedia.org/wiki/Adaptive_replacement_cache">ARC</a>（Adaptive Replacement Cache）、<a href="https://en.wikipedia.org/wiki/LIRS_caching_algorithm">LIRS</a>（Low Inter-Reference Recency Set）与基础的 LFU 策略之间的对比：</p>
<p><img src="https://raw.githubusercontent.com/ben-manes/caffeine/master/wiki/efficiency/search.png" alt="img"></p>
<p>在搜索场景中，三种高级策略的命中率较为接近于理想曲线（Optimal），而 LRU 则差距最远，<a href="https://github.com/ben-manes/caffeine/wiki/Efficiency">Caffeine 官方给出的</a>数据库、网站、分析类等应用场景中，这几种策略之间的绝对差距不尽相同，但相对排名基本上没有改变，最基础的淘汰策略的命中率是最低的。</p>
<p>其他缓存淘汰策略可以参考<a href="https://en.wikipedia.org/wiki/Cache_replacement_policies">Cache Replacement Policies</a>。</p>
<h3 id="extended-functionality">Extended functionality</h3>
<p>缓存除了基本读写功能外，还提供哪些额外的管理功能，譬如最大容量、失效时间、失效事件、命中率统计，等等。</p>
<p>一般来说，一套标准的 Map 接口（<a href="https://jcp.org/en/jsr/detail?id=107">JSR 107</a>  javax.cache.Cache / System.Runtime.Caching Namespace）就可以满足缓存访问的基本需要，不过在“访问”之外，专业的缓存往往还会提供很多额外的功能。</p>
<ul>
<li><strong>加载器</strong>：许多缓存都有“CacheLoader”之类的设计，加载器可以让缓存从只能被动存储外部放入的数据，变为能够主动通过加载器去加载指定 Key 值的数据，加载器也是实现自动刷新功能的基础前提。</li>
<li><strong>淘汰策略</strong>：有的缓存淘汰策略是固定的，也有一些缓存能够支持用户自己根据需要选择不同的淘汰策略。</li>
<li><strong>失效策略</strong>：要求缓存的数据在一定时间后自动失效（移除出缓存）或者自动刷新（使用加载器重新加载）。</li>
<li><strong>事件通知</strong>：缓存可能会提供一些事件监听器，让你在数据状态变动（如失效、刷新、移除）时进行一些额外操作。有的缓存还提供了对缓存数据本身的监视能力（Watch 功能）。</li>
<li><strong>并发级别</strong>：对于通过分段加锁来实现的缓存（以 Guava Cache 为代表），往往会提供并发级别的设置。可以简单将其理解为缓存内部是使用多个 Map 来分段存储数据的，并发级别就用于计算出使用 Map 的数量。如果将这个参数设置过大，会引入更多的 Map，需要额外维护这些 Map 而导致更大的时间和空间上的开销；如果设置过小，又会导致在访问时产生线程阻塞，因为多个线程更新同一个 ConcurrentMap 的同一个值时会产生锁竞争。</li>
<li><strong>容量控制</strong>：缓存通常都支持指定初始容量和最大容量，初始容量目的是减少扩容频率，这与 Map 接口本身的初始容量含义是一致的。最大容量类似于控制 Java 堆的-Xmx 参数，当缓存接近最大容量时，会自动清理掉低价值的数据。</li>
<li><strong>引用方式</strong>：支持将数据设置为软引用或者弱引用，提供引用方式的设置是为了将缓存与 Java 虚拟机的垃圾收集机制联系起来。</li>
<li><strong>统计信息</strong>：提供诸如缓存命中率、平均加载时间、自动回收计数等统计。</li>
<li><strong>持久化</strong>：支持将缓存的内容存储到数据库或者磁盘中，进程内缓存提供持久化功能的作用不是太大，但分布式缓存大多都会考虑提供持久化功能。</li>
</ul>
<h3 id="distributed-support">Distributed support</h3>
<p>缓存可分为“进程内缓存（In-memory cache）”和“分布式缓存（Distributed cache）”两大类，前者只为节点本身提供服务，无网络访问操作，速度快但缓存的数据不能在各个服务节点中共享，后者则相反。</p>
<p>相比起缓存数据在进程内存中读写的速度，一旦涉及网络访问，由网络传输、数据复制、序列化和反序列化等操作所导致的延迟要比内存访问高得多，所以对分布式缓存来说，处理与网络有相关的操作是对吞吐量影响更大的因素，往往也是比淘汰策略、扩展功能更重要的关注点。在决定使用哪种分布式缓存前，首先必须明确需求是什么？</p>
<ul>
<li>从访问的角度来说，如果是频繁更新但甚少读取的数据，通常是不会有人把它拿去做缓存的，因为这样做没有收益。对于甚少更新但频繁读取的数据，理论上更适合做复制式缓存；对于更新和读取都较为频繁的数据，理论上就更适合做集中式缓存。
<ul>
<li><strong>复制式缓存</strong>：复制式缓存可以看作是“能够支持分布式的进程内缓存”，它的工作原理与 Session 复制类似。缓存中所有数据在分布式集群的每个节点里面都存在有一份副本，读取数据时无须网络访问，直接从当前节点的进程内存中返回，理论上可以做到与进程内缓存一样高的读取性能；当数据发生变化时，就必须遵循复制协议，将变更同步到集群的每个节点中，复制性能随着节点的增加呈现平方级下降，变更数据的代价十分高昂。</li>
<li><strong>集中式缓存</strong>：集中式缓存是目前分布式缓存的主流形式，集中式缓存的读、写都需要网络访问，其好处是不会随着集群节点数量的增加而产生额外的负担，其坏处自然是读、写都不再可能达到进程内缓存那样的高性能。集中式缓存还有一个必须提到的关键特点，它与使用缓存的应用分处在独立的进程空间中，其好处是它能够为异构语言提供服务，但其坏处是如果要缓存对象等复杂类型的话，基本上就只能靠序列化来支撑具体语言的类型系统（支持 Hash 类型的缓存，可以部分模拟对象类型），不仅有序列化的成本，还很容易导致传输成本也显著增加。如今<a href="https://redis.io/">Redis</a>广为流行，基本上已经成为集中式缓存的首选，甚至可以说成为了分布式缓存的实质上的首选，几乎到了不必管读取、写入哪种操作更频繁，都可以无脑上 Redis 的程度。尽管 Redis 最初设计的本意是 NoSQL 数据库而不是专门用来做缓存的，可今天它确实已经成为许多分布式系统中无可或缺的基础设施，广泛用作缓存的实现方案。</li>
</ul>
</li>
<li>从数据一致性角度说，缓存本身也有集群部署的需求，理论上你应该认真考虑一下是否能接受不同节点取到的缓存数据有可能存在差异。譬如刚刚放入缓存中的数据，另外一个节点马上访问发现未能读到；刚刚更新缓存中的数据，另外一个节点访问在短时间内读取到的仍是旧的数据，等等。根据分布式缓存集群是否能保证数据一致性，可以将它分为 AP 和 CP 两种类型。实际开发中通常不太会把追求强一致性的数据使用缓存来处理，可以这样做，但是没必要（可类比 MESI 等缓存一致性协议）。譬如，Redis 集群就是典型的 AP 式，有着高性能高可用等特点，却并不保证强一致性。而能够保证强一致性的 ZooKeeper、Doozerd、Etcd 等分布式协调框架，通常不会有人将它们当为“缓存框架”来使用，这些分布式协调框架的吞吐量相对 Redis 来说是非常有限的。不过 ZooKeeper、Doozerd、Etcd 倒是常与 Redis 和其他分布式缓存搭配工作，用来实现其中的通知、协调、队列、分布式锁等功能。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220719165815033.png" alt="image-20220719165815033"></p>
<!-- raw HTML omitted -->
<p>分布式缓存与进程内缓存各有所长，也有各有局限，它们是互补而非竞争的关系，如有需要，完全可以同时把进程内缓存和分布式缓存互相搭配，构成透明多级缓存。使用进程内缓存做一级缓存，分布式缓存做二级缓存，如果能在一级缓存中查询到结果就直接返回，否则便到二级缓存中去查询，再将二级缓存中的结果回填到一级缓存，以后再访问该数据就没有网络请求了。如果二级缓存也查询不到，就发起对最终数据源的查询，将结果回填到一、二级缓存中去。</p>
<p>尽管多级缓存结合了进程内缓存和分布式缓存的优点，但它的代码侵入性较大，需要由开发者承担多次查询、多次回填的工作，也不便于管理，如超时、刷新等策略都要设置多遍，数据更新更是麻烦，很容易会出现各个节点的一级缓存、以及二级缓存里数据互相不一致的问题。必须“透明”地解决以上问题，多级缓存才具有实用的价值。一种常见的设计原则是变更以分布式缓存中的数据为准，访问以进程内缓存的数据优先。大致做法是当数据发生变动时，在集群内发送推送通知（简单点的话可采用 Redis 的 PUB/SUB，求严谨的话引入 ZooKeeper 或 Etcd 来处理），让各个节点的一级缓存自动失效掉相应数据。当访问缓存时，提供统一封装好的一、二级缓存联合查询接口，接口外部是只查询一次，接口内部自动实现优先查询一级缓存，未获取到数据再自动查询二级缓存的逻辑。</p>
<h2 id="risks">Risks</h2>
<h3 id="cache-penetration">Cache Penetration</h3>
<p>缓存的目的是为了缓解 CPU 或者 I/O 的压力，譬如对数据库做缓存，大部分流量都从缓存中直接返回，只有缓存未能命中的数据请求才会流到数据库中，这样数据库压力自然就减小了。但是如果查询的数据在数据库中根本不存在的话，缓存里自然也不会有，这类请求的流量每次都不会命中，每次都会触及到末端的数据库，缓存就起不到缓解压力的作用了，这种查询不存在数据的现象被称为缓存穿透。</p>
<p>缓存穿透有可能是业务逻辑本身就存在的固有问题，也有可能是被恶意攻击的所导致，为了解决缓存穿透，通常会采取下面两种办法：</p>
<ol>
<li>对于业务逻辑本身就不能避免的缓存穿透，可以约定在一定时间内对返回为空的 Key 值依然进行缓存（注意是正常返回但是结果为空，不应把抛异常的也当作空值来缓存了，并且该缓存过期时间应很短，最长不超过五分钟）， 读取时可从缓存中获取该空缓存，而不会访问数据库读取空值，使得在一段时间内缓存最多被穿透一次。如果后续业务在数据库中对该 Key 值插入了新记录，那应当在插入之后主动清理掉缓存的 Key 值。如果业务时效性允许的话，也可以将对缓存设置一个较短的超时时间来自动处理。</li>
<li>对于恶意攻击导致的缓存穿透，通常会在缓存之前设置一个布隆过滤器来解决。所谓恶意攻击是指请求者刻意构造数据库中肯定不存在的 Key 值，然后发送大量请求进行查询。布隆过滤器是用最小的代价来判断某个元素是否存在于某个集合的办法。布隆过滤器将所有可能存在的数据哈希到一个足够大的 bitmap 中，如果布隆过滤器给出的判定结果是请求的数据不存在，那就直接返回即可，连缓存都不必去查。虽然维护布隆过滤器本身需要一定的成本，但比起攻击造成的资源损耗仍然是值得的。</li>
<li>缓存预热（Cache Warm-up），系统上线时，将相关的缓存数据直接加载到缓存系统，避免在用户请求查询数据库时对数据缓存。用户请求会查询事先被预热的缓存数据。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/KrisNie/ImageHosting/main/Blog/image-20220719172251634.png" alt="image-20220719172251634"></p>
<h3 id="cache-breakdown">Cache Breakdown</h3>
<p>我们都知道缓存的基本工作原理是首次从真实数据源加载数据，完成加载后回填入缓存，以后其他相同的请求就从缓存中获取数据，缓解数据源的压力。如果缓存中某些热点数据忽然因某种原因失效了，譬如典型地由于超期而失效，此时又有多个针对该数据的请求同时发送过来，这些请求将全部未能命中缓存，都到达真实数据源中去，导致其压力剧增，这种现象被称为缓存击穿。要避免缓存击穿问题，通常会采取下面的两种办法：</p>
<ol>
<li>加锁同步，以请求该数据的 Key 值为锁，使得只有第一个请求可以流入到真实的数据源中，其他线程采取阻塞或重试策略。如果是进程内缓存出现问题，施加普通互斥锁即可，如果是分布式缓存中出现的问题，就施加分布式锁，这样数据源就不会同时收到大量针对同一个数据的请求了。</li>
<li>热点数据由代码来手动管理，缓存击穿是仅针对热点数据被自动失效才引发的问题，对于这类数据，可以直接由开发者通过代码来有计划地完成更新、失效，避免由缓存的策略自动管理。</li>
</ol>
<h3 id="cache-avalanche">Cache Avalanche</h3>
<p>缓存击穿是针对单个热点数据失效，由大量请求击穿缓存而给真实数据源带来压力。有另一种可能是更普遍的情况，不需要是针对单个热点数据的大量请求，而是由于大批不同的数据在短时间内一起失效，导致了这些数据的请求都击穿了缓存到达数据源，同样令数据源在短时间内压力剧增。</p>
<p>出现这种情况，往往是系统有专门的缓存预热功能，也可能大量公共数据是由某一次冷操作加载的，这样都可能出现由此载入缓存的大批数据具有相同的过期时间，在同一时刻一起失效。还有一种情况是缓存服务由于某些原因崩溃后重启，此时也会造成大量数据同时失效，这种现象被称为缓存雪崩。要避免缓存雪崩问题，通常会采取下面的三种办法：</p>
<ol>
<li>提升缓存系统可用性，建设分布式缓存的集群。</li>
<li>启用透明多级缓存，各个服务节点一级缓存中的数据通常会具有不一样的加载时间，也就分散了它们的过期时间。</li>
<li>将缓存的生存期从固定时间改为一个时间段内的随机时间，譬如原本是一个小时过期，那可以缓存不同数据时，设置生存期为 55 分钟到 65 分钟之间的某个随机时间。</li>
</ol>
<h3 id="cache-pollution">Cache Pollution</h3>
<p>缓存污染是指缓存中的数据与真实数据源中的数据不一致的现象。尽管笔者在前面是说过缓存通常不追求强一致性，但这显然不能等同于缓存和数据源间连最终的一致性都可以不要求了。</p>
<p>缓存污染多数是由开发者更新缓存不规范造成的，譬如你从缓存中获得了某个对象，更新了对象的属性，但最后因为某些原因，譬如后续业务发生异常回滚了，最终没有成功写入到数据库，此时缓存的数据是新的，数据库中的数据是旧的。为了尽可能的提高使用缓存时的一致性，已经总结不少更新缓存可以遵循设计模式，譬如 Cache Aside、Read/Write Through、Write Behind Caching 等。其中最简单、成本最低的 Cache Aside 模式是指：</p>
<ul>
<li>读数据时，先读缓存，缓存没有的话，再读数据源，然后将数据放入缓存，再响应请求。</li>
<li>写数据时，先写数据源，然后失效（而不是更新）掉缓存。</li>
</ul>
<p>读数据方面一般没什么出错的余地，但是写数据时，就有必要专门强调两点：一是先后顺序是先数据源后缓存。试想一下，如果采用先失效缓存后写数据源的顺序，那一定存在一段时间缓存已经删除完毕，但数据源还未修改完成，此时新的查询请求到来，缓存未能命中，就会直接流到真实数据源中。这样请求读到的数据依然是旧数据，随后又重新回填到缓存中。当数据源的修改完成后，结果就成了数据在数据源中是新的，在缓存中是老的，两者就会有不一致的情况。另一点是应当失效缓存，而不是去尝试更新缓存，这很容易理解，如果去更新缓存，更新过程中数据源又被其他请求再次修改的话，缓存又要面临处理多次赋值的复杂时序问题。所以直接失效缓存，等下次用到该数据时自动回填，期间无论数据源中的值被改了多少次都不会造成任何影响。</p>
<p>Cache Aside 模式依然是不能保证在一致性上绝对不出问题的，否则就无须设计出<a href="http://icyfenix.cn/distribution/consensus/paxos.html">Paxos</a>这样复杂的共识算法了。典型的出错场景是如果某个数据是从未被缓存过的，请求会直接流到真实数据源中，如果数据源中的写操作发生在查询请求之后，结果回填到缓存之前，也会出现缓存中回填的内容与数据库的实际数据不一致的情况。但这种情况的概率是很低的，Cache Aside 模式仍然是以低成本更新缓存，并且获得相对可靠结果的解决方案。</p>
<h1 id="reference">Reference</h1>
<ol>
<li><a href="http://icyfenix.cn/architect-perspective/general-architecture/diversion-system/">透明多级分流系统</a></li>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/performance/caching/distributed?view=aspnetcore-6.0">Distributed caching in ASP.NET Core | Microsoft Docs</a></li>
<li><a href="https://www.alachisoft.com/ncache/aspnet-core-idistributedcache-ncache.html">NCache as IDistributed Cache provider for ASP.NET Core applications (alachisoft.com)</a></li>
</ol>

                    
                    <HR width="100%" id="EOF">
		    <p style="color:#777;">Last modified on 2021-12-01</p>
                    
                </div>
            </div>
            
            
            <nav class="post-pagination">

                
                <a class="newer-posts" href="https://www.openheart.icu/computing-science/transactions/">
			Next<br>Transactions
                </a>
                
                
                
                <a class="older-posts" href="https://www.openheart.icu/computing-science/remote-procedure-call/">
			Previous<br>Remote Procedure Call
                </a>
                
            </nav>
            <div class="post-comment-wrapper">
                


<div id="gitalk-container"></div>









            </div>
        </div>
    </div>


                    </div>
            </div><div id="single-column-footer">
	
	<i class="fa fa-weixin" aria-hidden="true"></i>
	QuadragintaDuo
	<br>
	<i class="fa fa-envelope" aria-hidden="true"></i>
	krisnie42@qq.com
	<br>
		site pv:<span id="busuanzi_value_site_pv_m"></span>
	| 
		site uv:<span id="busuanzi_value_site_uv_m"></span>
	<br>
	鲁ICP备20007116号
	<br>
	Powered by Hugo | Theme - <a href="https://github.com/amazingrise/hugo-theme-diary">Diary</a>
	
	<br>
	
	
	&copy;
		
		2022 ALL RIGHTS RESERVED KRIS NIE
		
	<script>
		$(function(){
			$("#busuanzi_value_site_uv").bind('DOMNodeInserted',function(e){
				console.log('DOMNodeInserted');
				debugger;
				$('#busuanzi_value_site_uv_m').after($('#busuanzi_value_site_uv').text()); 
				$('#busuanzi_value_site_pv_m').after($('#busuanzi_value_site_pv').text());
			});
		})
	</script>
</div>
            </div>
    
    <script src="/js/journal.js"></script>
    </body>
</html>
