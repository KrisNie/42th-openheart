<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Interview on 42th openheart</title>
    <link>https://www.openheart.icu/tags/interview/</link>
    <description>Recent content in Interview on 42th openheart</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>ALL RIGHTS RESERVED KRIS NIE</copyright>
    <lastBuildDate>Sat, 25 Jul 2020 18:32:23 +0000</lastBuildDate><atom:link href="https://www.openheart.icu/tags/interview/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Static Search Table &amp; Dynamic Search Table</title>
      <link>https://www.openheart.icu/cs/%E5%8A%A8%E6%80%81%E6%9F%A5%E6%89%BE%E8%A1%A8%E4%B8%8E%E9%9D%99%E6%80%81%E6%9F%A5%E6%89%BE%E8%A1%A8/</link>
      <pubDate>Sat, 25 Jul 2020 18:32:23 +0000</pubDate>
      
      <guid>https://www.openheart.icu/cs/%E5%8A%A8%E6%80%81%E6%9F%A5%E6%89%BE%E8%A1%A8%E4%B8%8E%E9%9D%99%E6%80%81%E6%9F%A5%E6%89%BE%E8%A1%A8/</guid>
      <description>今天在看BST时，指导书上讲二叉排序树时与二分查找进行对比，引出几个模棱两可的概念（静态查找表、动态查找表），经查找后整理得本文
概述 首先要了解几个基础概念
查找(Searching) 是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素。
查找表(Search Table) 是由同⼀类型的数据元素(记录)构成的集合。
关键字(Key) 是数据元素中某个数据项的值，又称为键值，用它可以表示⼀个数据元素，也可以标识一个记录的某个数据项(字段)，我们称为关键码。 若关键字可以唯⼀地标识一个记录, 则称此关键字为主关键字 (Primary Key)。 对于那些可以识别多个属于元素(记录)的关键字，我们称为次关键字(Secondary Key)。
查找表操作可分为静态查找和动态查找。
静态查找表(Static Search Table) 只作查找操作的查找表。
 查询某个”特定的”数据元素是否在查找表中; 检索某个&amp;quot;特定的&amp;quot;数据元素和各种属性;  静态查找只是仅查找，并不会去改变集合内的数据元素。常用的查找有。
顺序查找（ Linear search，又称线性查找）  原理 ：顺序查找就是按顺序从头到尾依次往下查找，从表中的第一个(或最后一个)记录开始，逐个进行记录关键字和给定值比较，找到数据，则提前结束查找，找不到便一直查找下去，直到数据最后一位
 public static int linearSearch(int[] a, int num) { for(int i = 0; i &amp;lt; a.length; i++) { if(a[i] == num){ // 返回数据所在的下标，也就是位置  return i; } } // 不存在的话返回-1  return -1; } 索引顺序表查找（分块查找） 整个表中的元素未必有序，但若划分为若干块后，每一块中的所有元素均小于（或大于）其后面块中的所有元素。我们称这种为分块有序。
分块查找要求把一个数据分为若干块，每一块里面的元素可以是无序的，但是块与块之间的元素需要是有序的。（对于一个非递减的数列来说，第i块中的每个元素一定比第i-1块中的任意元素大）
 原理：</description>
    </item>
    
    <item>
      <title>Implementing the Singleton Pattern in C#</title>
      <link>https://www.openheart.icu/cs/implementing-the-singleton-pattern-in-csharp/</link>
      <pubDate>Sat, 25 Jul 2020 00:14:11 +0000</pubDate>
      
      <guid>https://www.openheart.icu/cs/implementing-the-singleton-pattern-in-csharp/</guid>
      <description>Implementing the Singleton Pattern in C# 在C＃中实现单例模式。该模式是非常常见的设计模式之一，某个对象全局只需要一个实例时，就可以使用单例模式。它的优点也显而易见：
 它能够避免对象重复创建，节约空间并提升效率 避免由于操作不同实例导致的逻辑错误  以下是原文作者Jon Skeet 对C#单例模式的介绍。
Introduction 单例模式是软件工程中最著名的模式之一。本质上，单例是仅允许创建其自身的单个实例的类，并且通常提供对该实例的简单访问。最常见的是，单例在创建实例时不允许指定任何参数，否则对实例的第二次请求但参数不同可能会出现问题！ （如果应该为具有相同参数的所有请求访问相同的实例，则使用工厂模式更为合适。）本文仅涉及不需要参数的情况。通常，单例的要求是它们是懒惰地创建的，即：直到首次需要实例时才创建实例。
在C＃中有多种不同的方式来实现单例模式。我将在这里以从简到难顺序（in reverse order of elegance）介绍它们，从最常见的线程安全性开始，逐步发展为完全延迟加载，线程安全，简单且高性能的版本。
所有这些实现都有四个共同的特征，但是：
 单个构造函数，私有且无参数。这样可以防止其他类实例化它（这将违反模式）。请注意，它还防止了子类化（subclassing）如果一个单例可以被子类化一次，则可以被子类化两次，并且如果每个子类都可以创建一个实例，则将违反（violated）该模式。如果您需要基本类型的单个实例，则可以使用工厂模式，但是直到运行时才知道确切的类型。 该类是密封的。严格来说，由于上述几点，这是不必要的，但可以帮助JIT进行更多优化。 一个静态变量，其中包含对创建的单个实例的引用（如果有）。 公共静态方法是获取对创建的单个实例的引用，并在必要时创建一个实例。  请注意，所有这些实现还使用公共静态属性Instance作为访问实例的方式。在所有情况下，都可以轻松地将属性转换为方法，而不会影响线程安全性或性能。
First version - not thread-safe // Bad code! Do not use! public sealed class Singleton { private static Singleton instance = null; private Singleton() { } public static Singleton Instance { get { if (instance == null) { instance = new Singleton(); } return instance; } } } 如前所述，以上内容不是线程安全的。</description>
    </item>
    
    <item>
      <title>Distributed cache</title>
      <link>https://www.openheart.icu/cs/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:50 +0000</pubDate>
      
      <guid>https://www.openheart.icu/cs/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</guid>
      <description>简单了解分布式缓存的各种概念
缓存雪崩 缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都去查询数据库了，而对数据库 CPU 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。
关键词：缓存失效，针对这种情况一般有三种处理办法：
 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。 为 key 设置不同的缓存失效时间。  第二、第三中方法在面试中均被提到过，很遗憾我只想到了第一种解决办法（纯粹靠蒙） 😁
缓存穿透 缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在 缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。
有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈 希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存 储系统的查询压力。
另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不 存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。
缓存预热 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据。
缓存更新 缓存更新除了缓存服务器自带的缓存失效策略之外（Redis 默认的有 6 中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：
（1）定时去清理过期的缓存；
（2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。
缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 降级的最终目的是保证核心服务可用，即使是有损的。 而且有些服务是无法降级的（如加入购物车、结算）。</description>
    </item>
    
    <item>
      <title>Reliability&amp;Availability</title>
      <link>https://www.openheart.icu/cs/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7%E5%92%8C%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7/</link>
      <pubDate>Fri, 24 Jul 2020 00:00:50 +0000</pubDate>
      
      <guid>https://www.openheart.icu/cs/%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7%E5%92%8C%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7/</guid>
      <description>区分高可靠性与高可用性 Reliability和Availability分别对应可靠性和可用性, 这两个概念既有区别也有联系:
 Reliability定义为一个服务连续无故障运行的时间，无故障运行的时间越长，可靠性就越高。 Availiability定义为在足够长的时间里，比如一年的时间里，一个服务可用的时间，服务可用时间越长越好。一般用可服务时间除于总时间算出一个百分比，用百分比作为度量。比如一个服务如果有5个9的可用性，指的就是一年里99.999%时间里服务都是可用的。  有两个极端的例子可以很好的说明这两个概念的区别:
 假想一个服务，可靠性很高，平均来说可以稳定运行10年，但是一旦服务中断，要用一年的时间来恢复，那么它的可用性只有90%。 假想另一个服务，可靠性很差，运行10秒就会宕机，但是恢复服务只需要1ms, 那么它的可用性是99.99%  从这两个极端的例子可以看出，提高可用性有两条路:
 一是提高可靠性，当然影响可靠性的原因有很多，包括硬件，软件，网络，运维等。但是有人做过统计，软件的bug是影响可靠性的最主要的因素。并且提高软件质量相较于使用更可靠的硬件也算成本较低的方式了， 二是减少恢复时间，一旦出现宕机，如果能在秒级恢复，那对业务影响是很小的。   高可靠性的实现 &amp;hellip;
 高可用性的实现 高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。
在设计高可用性策略时应该首先考虑下述因素 ​ • RTO（Recovery Time Objective）-也就是恢复时间目标，意味着允许多少宕机时间，通常用几个9表示，比如说99.999%的可用性意味着每年的宕机时间不超过5分钟、99.99%的可用性意味着每年的宕机时间不超过52.5分钟、99.9%的可用性意味着每年的宕机时间不超过8.75小时。值得注意的是，RTO的计算方法要考虑系统是24*365，还是仅仅是上午6点到下午9点等。您还需要注意是否维护窗口的时间在算在宕机时间之内，如果允许在维护窗口时间进行数据库维护和打补丁，则更容易实现更高的可用性。
​ • RPO（Recovery Point Objective）-也就是恢复点目标，意味着允许多少数据损失。通常只要做好备份，可以比较容易的实现零数据损失。但当灾难发生时，取决于数据库损坏的程度，从备份恢复数据所需要的时间会导致数据库不可用，这会影响RTO的实现。一个早期比较著名的例子是某欧美的银行系统，只考虑的RPO，系统里只存在了完整备份和日志备份，每3个月一次完整备份，每15分钟一次日志备份，当灾难发生时，只能够通过完整备份和日志备份来恢复数据，因此虽然没有数据丢失，但由于恢复数据花了整整两天时间，造成银行系统2天时间不可用，因此流失了大量客户。另外一个相反的例子是国内某在线视频网站，使用SQL Server作为后端关系数据库，前端使用了No-SQL，定期将No-SQL的数据导入关系数据库作为备份，当灾难发生时最多允许丢失一天的数据，但是要保证高可用性。
高可用的实现 整个互联网分层系统架构的高可用，又是通过每一层的冗余+自动故障转移来综合实现的，具体的：
 【客户端层】到【反向代理层】的高可用，是通过反向代理层的冗余实现的，常见实践是keepalived + virtual IP自动故障转移 【反向代理层】到【站点层】的高可用，是通过站点层的冗余实现的，常见实践是nginx与web-server之间的存活性探测与自动故障转移 【站点层】到【服务层】的高可用，是通过服务层的冗余实现的，常见实践是通过service-connection-pool来保证自动故障转移 【服务层】到【缓存层】的高可用，是通过缓存数据的冗余实现的，常见实践是缓存客户端双读双写，或者利用缓存集群的主从数据同步与sentinel保活与自动故障转移；更多的业务场景，对缓存没有高可用要求，可以使用缓存服务化来对调用方屏蔽底层复杂性 【服务层】到【数据库“读”】的高可用，是通过读库的冗余实现的，常见实践是通过db-connection-pool来保证自动故障转移 【服务层】到【数据库“写”】的高可用，是通过写库的冗余实现的，常见实践是keepalived + virtual IP自动故障转移  SQlServer所支持的高可用特性 SQL Server中所支持的高可用性功能与版本息息相关，企业版支持所有的高可用性功能，这些功能包括：
 故障转移集群 数据库镜像（在SQL Server 2012中被标记为“过时”） 事务日志传送 数据库快照 AlwaysOn可用性组 热加载内存 在线索引操作 数据库部分在线（只还原了主文件组或主文件组和额外的NDF文件）  故障转移集群  故障转移集群为整个SQL Server实例提供高可用性支持，这意味着在集群上某个节点的SQL Server实例发生了硬件错误、操作系统错误等会故障转移到该集群上的其它节点。通过多个服务器（节点）共享一个或多个磁盘来实现高可用性，故障转移集群在网络中出现的方式就像单台计算机一样，但是具有高可用特性。值得注意的是，由于故障转移集群是基于共享磁盘，因此会存在磁盘单点故障，因此需要在磁盘层面部署SAN复制等额外的保护措施。常见的故障转移集群是双节点的故障转移集群，包括主主节点和主从节点。  事务日志传送   事务日志传送提供了数据库级别的高可用性保护。日志传送可用来维护相应生产数据库（称为“主数据库”）的一个或多个备用数据库（称为“辅助数据库”）。发生故障转移之前，必须通过手动应用全部未还原的日志备份来完全更新辅助数据库。日志传送具有支持多个备用数据库的灵活性。如果需要多个备用数据库，可以单独使用日志传送或将其作为数据库镜像的补充。当这些解决方案一起使用时，当前数据库镜像配置的主体数据库同时也是当前日志传送配置的主数据库。</description>
    </item>
    
    <item>
      <title>.NET INTERVIEW</title>
      <link>https://www.openheart.icu/cs/dot-net-interview/</link>
      <pubDate>Fri, 17 Jul 2020 23:28:00 +0000</pubDate>
      
      <guid>https://www.openheart.icu/cs/dot-net-interview/</guid>
      <description>.NET INTERVIEW from Jeffrey Zhao&amp;rsquo;s blog 我在面试.NET/C#程序员时会提出的问题
 什么是.NET？什么是CLI？什么是CLR？IL是什么？JIT是什么，它是如何工作的？GC是什么，简述一下GC的工作方式？ 什么是.net .NET是个平台，你就把它看成C#
一个.NET应用是一个运行于.NET Framework之上的应用程序。（更精确的说，一个.NET应用是一个使用.NET Framework类库来编写，并运行于公共语言运行时 Common Language Runtime之上的应用程序。）如果一个应用程序跟.NET Framework无关，它就不能叫做.NET程序。比如，仅仅使用了XML并不就是.NET应用，仅仅使用SOAP SDK调用一个Web Service也不是.NET应用
开发平台（Dot Net Framework）：包含通用语言运行时（CLR）和Dot Net框架类库（FCL）两个部分。他们提供了一致的编程模型，简化的编程方式，可靠的版本机制（用全局程序集缓存GAC来避免DLL Hell），轻便的部署管理（程序集自带的元数据可以避免ini文件和注册表） ，广泛的平台支持（只要这台机器兼容标准下的CLR和FCL就可以部署，当然运行的时候IL会变成本机代码），无缝的语言集成，自动化的内存管理（垃圾收集），类型安全（CLR会阻止利用缓冲区溢出错误进行的攻击），CLR支持跨语言调试，统一的错误报告，全新的安全策略（CAS），兼容以往的COM组件
什么是CLR CLR(公用语言运行时)和Java虚拟机一样也是一个运行时环境，它负责资源管理（内存分配和垃圾收集），并保证应用和底层操作系统之间必要的分离。.NET Framework 提供了一个称为公共语言运行时的运行时环境**（Commen Language Runtime）**，它运行代码并提供使开发过程更轻松的服务。公共语言运行时的功能通过编译器和工具公开，你可以编写利用此托管执行环境的代码。 使用基于公共语言运行时的语言编译器开发的代码称为托管代码；托管代码具有许多优点，例如：跨语言集成、跨语言异常处理、增强的安全性、版本控制和部署支持、简化的组件交互模型、调试和分析服务等。
什么是CLI 通用语言基础结构（Common Language Infrastructure，CLI）是CLR的一个子集，也就是.NET中最终对编译成MSIL代码的应用程序的运行环境进行管理的那一部分。在 CLR结构图中CLI位于下半部分，主要包括类加载器(Class Loader)、实时编译器(IL To Native Compilers)和一个运行时环境的垃圾收集器(Garbage Collector)。CLI是.Net和CLR的灵魂，CLI为IL代码提供运行的环境，你可以将使用任何语言编写的代码通过其特定的编译器转换为 MSIL代码之后运行其上，甚至还可以自己写MSIL代码在CLI上面运行。
什么是IL IL是微软.NET平台上衍生出来的一门中间语言，.NET平台上的各种高级语言（如C#，VB，F#）的编译器会将各自的文字表述方式转化为 IL。各种不同的文字形式最终被统一到了IL的表述方式，其中包含了.NET平台上的各种元素，如“范型”，“类”、、“接口”、“模块”、“属性”等 等。值得注意的是，各种高级语言本身可能根本没有这些“概念”在里头，如IronScheme是一个在.NET平台上的Scheme语言实现，其中根本没有前面提到的这些IL——亦或说是.NET平台上的名词。IL本身并不知道自己是由哪种高级语言转化而来的，哪种语言中有哪些特性，IL也根本不会关心。
什么是JIT JIT（Just In Time, JIT）是.Net边运行边编译的一种机制。
开发人员需要通过IL与CLR进行交流，虽然IL本身支持一些面向对象的概念，但是对于开发人员来讲还是过于复杂低效，于是C#应运而生，程序员只需编写C#代码，csc编译器会将其翻译成IL；虽然CLR理解IL，但是CPU只认识二进制指令，所以CLR需要JIT的帮助，将IL翻译成CPU指令. JIT按需工作，当一个.NET方法即将被执行时，JIT会介入，把该方法（IL指令）编译成CPU指令，并保存以供重用。
什么是GC，以及它的工作方式 GC:.NET Framework 的垃圾回收器管理应用程序的内存分配和释放
分配内存 初始化新进程时，运行时会为进程保留一个连续的地址空间区域。 这个保留的地址空间被称为托管堆。 托管堆维护着一个指针，用它指向将在堆中分配的下一个对象的地址。 最初，该指针设置为指向托管堆的基址。 托管堆上包含了所有引用类型。 应用程序创建第一个引用类型时，将为托管堆的基址中的类型分配内存。 应用程序创建下一个对象时，垃圾回收器在紧接第一个对象后面的地址空间内为它分配内存。 只要地址空间可用，垃圾回收器就会继续以这种方式为新对象分配空间。
从托管堆中分配内存要比非托管内存分配速度快。 由于运行时通过为指针添加值来为对象分配内存，所以这几乎和从堆栈中分配内存一样快。 另外，由于连续分配的新对象在托管堆中是连续存储，所以应用程序可以快速访问这些对象。</description>
    </item>
    
  </channel>
</rss>
